---
title: "14.123 - Microeconomic Theory III"
output: html_document
---

# Study Guide{.tabset}

## **Lectures**{.tabset}

### **L1** 

#### **Static Deterministic Choice and Revealed Preference**

**Summary**: first lecture reviews the basics such as what are choices, preferences, revealed preferences and utility representations. It introduces preference relations and how those can be mapped to a utility function, while talking about rationality and WARP. 

- **Completeness**$^{12}$: for every set of alternatives(menus) X: agents know whether they prefer *x* or *y*. 

- **Transitive**$^{12}$: given *x*, *y* and *z*, if $x \succeq y$ and $y \succeq z$, then $x \succeq z$.

- **Rational**$^{13}$ = *Complete* + *Transitive*.

- **Anti-symmetric**$^{12}$: if $x \succeq y$ and $y \succeq x$, then *x* = *y*. 

- $^{15}$Every complete transitive preference defines a choice correspondence: $c_{\succeq}$(A) = \{ x $\in$ A : x $\succeq$ y $\forall y \in A$ \}.

- **Choice correspondence**: a map c:M(X) $\rightarrow$ M(X) s.t. c(A) $\subseteq$ A. c(A) gives the alternatives chosen when presented with menu A.

- **WARP**: if A,B $\in M$ and *x,y* $\in$ A $\cap$ B, $x \in C(A)$ and $y \in C(B)$ $\implies x \in C(B)$. In words, this means: 

    - WARP: implies Sen's $\alpha$: if $x \in A \subseteq B$ and $x \in C(B)$ $\implies$ $x \in C(A)$. 
    
    - **Weakly revealed preferred**: $\succeq^\ast$. If x $\succeq^\ast$ y $\implies$ x was chosen for any menu that contains *y*. 
    
    - **WARP** implies Arrow's C4: if A $\subseteq$ B and c(B) $\cap$ A $\neq$ $\varnothing$, then c(A) = c(B) $\cap$ A. WARP and C4 are equivalent if M = M(X).
    
- **Transitive closure**: when you can add terms between the relation x $\succeq^\ast$ y $\implies$ x $\succeq^\ast$ z $\succeq^\ast$ y.

- **Congruent**: if x $\succeq^\ast$ y and y $\in$ C(A) then x $\in$ C(A). In words, if *x* is revealed preferred to *y* and *y* is in the choice of *A* then *x* will also be in that choice too.

- **Utility preference**: $\forall$ x,y $\in$ X, x $\succeq$ y $\iff$ u(x) $\geq$ u(y). 

- **Debreu's Theorem**: if X is a convex subset of $\mathbb{R}^n$, then $\succeq$ is complete, transitive and continuous $\iff$ it has a representation by a continuous utility function. Proof sketch on slides 29-30.

- **Continuous**: upper and lower contour sets $\{ y \in X: y \succeq x \}$ and $\{ y \in X: x \succeq y \}$ are closed. 

- **Ordinal Utility**: if *u* represents $\succeq$, it is also represented by v $\iff$ there is a strictly increasing function $f: \mathbb{R} \rightarrow \mathbb{R}$ s.t. v = f $\circ$ u. In this sense, utility is **ordinal**: only the ordering matters (size matters not).

- **Continuous Revealed Preference Theory**: X = $\mathbb{R}^n_+$ free disposal menus equal budget sets. The data satisfies GARP. 

- **Afriat's Theorem**: if D is finite then the data satisfies GARP $\iff$ it can be generated by a continuous, concave, strictly increasing utility function.

- **Dense subset**$^{29}$:

- **Cardinal vs Ordinal preferences**$^{32}$:

#### **Proofs**

- Debreu (1954).

- Proof of utility representation: suppose $X$ is finite, then there is a utility function that represents $\succeq$ $\iff$ $\succeq$ is complete and transitive.

- Proof of Debreu 1954: slides 29-30.

### **L2**

Readings for L2: 

- Huber, Payne and Puto(1982).

- Huber, Payne and Puto(2014).

- Strzalecki 1.1-1.8; 5.1-5.2.

- MWG 6A-B.

#### **Testing Revealed Preference Theory I, Methodology**

**Summary**: how do we test the revealed preference theory? Counter-examples: decoy effect, attraction effect, compromise effect. Static decisions under risk: $\Delta (Z)$ lotteries $\rightarrow$ what is the expected utility of a lottery p $\in \Delta(Z)$? Independence axiom. Cardinal uniqueness ("unique up to affine transformations").  

- **Within-subject** experiment: same subject chooses among different menus.

- **Between-subject** experiment: compares choices of one set of people from menu A to those of another set of people from menu B.  

**Setting**: let **X** be a finite set of alternatives. Enumerate the elements of X, and represent each preference as a 1-to-1 map *u*: X = \{1,...,|X|\} $\rightarrow$ \{1,...,|X|\} (a permutation). **U** is the finite set of all such maps. **$\Delta (U)$** is the space of probability distributions on *U*, and let **v $\in \Delta (U)$** represent the actual distribution of preferences in the population. 

- From the setting above, the data is a **system of choice probabilities (P,X)**: for each choice set A we have $P_A \in \Delta (A)$. So a choice set A represents the actual distribution of preferences in the population. 

- **Rationalizable**: if choice probabilities can be generated by some v$\in$(U) then it's rationalizable. This means that if (P,X) is rationalizable for any x $\in$ X if x $\in$ A and A $\subseteq$ A' then P$_A$(x) $\geq$ P$_{A'}$(x). In words, if we give a larger choice set then choice probability/market shares of the originally available items cannot increase.

- **Regularity**: if the system of choice probabilities(P,X) is rationalizable $\implies$ $\forall x \in X$, if $x \in A$ and $A \subseteq A'$, then $P_A (x) \geq P_{A'}(x)$. The intuition is that by enlarging the set of choices presented to a individual, it can't increase the probability of him selecting an item from the original set. Some counter-examples:

- **Decoy Effect**: adding a "decoy" into a choice menu, a decoy that is dominated by one alternative but not by the other, can lead to violations of regularity and implies violations of WARP. For example, people might buy more US\$100 items when a US\$200 is added, instead of the US\$ 50 one. 

- **Compromise effect**: choose the "middle option". (Simonson 1989). Ex: adding a \$ 429 version of a product increased the sales of the \$ 275 model. 

- **Reference point**: an agent has a reference map $r: M \rightarrow X \cup \varnothing$, and when r(M) is non-empty, the agent restricts attention to choices *y* such that $U(y) \geq U(x)$ for all functions $U: X \rightarrow \mathbb{R}$ in a set $\mathcal{U}$.

##### **Static Decisions under "Risk" (Objectively Known Probabilities)**

- Z: finite (for now) set of "prizes/consequences". The idea is that you get prize f(s) is state s occurs. Since you don't know the state, you don't know which prize you'll get: it's random. $\mathcal{F} = Z^S$ denotes the set of random variables. Given the probability measure P, we can compute the 

- $\Delta(Z)$ are the probability distributions/lotteries on Z.(How the lottery is determined is irrelevant: 1/4 chance = 2 heads after flipping the coin twice.) $\Delta (Z)$ is convex; $\forall$ p,q $\in \Delta (Z)$ and a $\in$ [0,1], ap + 1 (1 - a)q $\in \Delta (Z)$ is the lottery that **assigns** probability ap(z) + (1 - a)q(z) to each $z \in Z$. (for more: Strzalecki pg 74)

- **Bernoulli Utility**: any function $u: Z \rightarrow \mathbb{R}$. 

- **Expected Utility of lottery p**: given $p \in \Delta (Z)$, the EU is U(p) = $\sum_{z \in Z} p(z)u(z)$. 

- $\succeq$ has an **expected utility representation**: if there is a Bernoulli utility function *u* such that $U(p) = \sum_{z \in Z}p(z)u(z)$ represents $\succeq$. 

- **Independence Axiom**: $\forall$ p,q,r, $\in \Delta$(Z) and $\alpha \in (0,]$ we have that $p \succeq q$ implies $\alpha p + (1 - \alpha) r \succ$ $\alpha q + (1 - \alpha) r$). Regardless of the weight you assign to r, the first option will always be preferred. 

- **Machinery for the EU Theorem**: given the outcomes Z are finite, the **Dirac measures** are a finite subset of $\Delta (Z)$. With complete and transitive preferences, there is a best Dirac measure: $\delta_B \succeq \delta_z \forall z \in Z$; and a worst Dirac measure $\delta_W$.

- **Morgenstern and von Neumann Theorem(1944)**: preference $\succeq$ on $\Delta (Z)$ has an EU representation $\iff$ it is complete, transitive, continuous and satisfies the Independence Axiom. - Check this proof.  

- **Consequentialism**: when nature rules out *r*, agent makes the same choice between *p* and *q*.

- **Dynamic consistency**: the agent makes same decisions in the 2 choice problems.

- **Dirac measure**: given Z is finite, the Dirac measures are a finite subset of $\Delta (Z)$. It has a worst and best Dirac so that $\delta_B \succeq p \succeq \delta_W$ for all p $\in \Delta(Z)$. 

- **Cardinal Uniqueness**: given 2 Bernoulli utility functions: *u* and *u'*, there is $a > 0$ and $b$ such that $\forall z \in Z$, u(z) = au'(z) + b and all such a,b give equivalent representations(unique up to affine transformations). Adding a constant or multiplying by some factor (as long as $a > 0$) to the utility of all outcomes won't change the ranking itself. <!-- This preserves the original ordering of the relation, but alters the magnitude. -->

- **Ordinal Uniqueness**:??

- **Jensen's Inequality**: an expected utility preference is risk averse/risk neutral/risk loving if *u* is concave/affine/convex.

- **CARA**(coefficient of absolute risk aversion): A(z) = $\frac{-u''(z)}{u'(z)}$.

#### **Proofs**:

- **von-Neumann Preferences**: preference $\succeq$ on $\Delta(Z)$ has an expected utility representation $\iff$ it's complete, transitive, continuous and has the independence axiom.

- **Cardinal uniqueness**.

### **L3**

Readings for L3: 

- Strzalecki 5.1-5.2.

- MWG 6A-C, optional 6D.

- Rabin (2000).

#### **Lotteries with Money Payoffs**

**Summary:** given EU representation of preference $\succeq$ on $\Delta (Z)$; coefficient of absolute risk aversion. Certain Equivalents. CARA preferences. Differentiating between risky and safe assets. Demand for insurance makes sense? Risk aversion: what are the stakes? Stochastic Dominance. 

- Let the expected value of p be: Ep = $\int$ zdF(z). Fix $\delta_{Ep}$ is the deterministic lottery that pays the expected value of lottery *p*. Preference $\succeq$ is:

    - **Risk averse** when $\delta_{Ep} \succeq p$, for all p.
    
    - **Risk neutral** when $\delta_{Ep} \sim p$, for all p.
    
    - **Risk loving** when $p \succeq \delta_{Ep}$, for all p.
    
- **Theorem**: Jensen's Inequality: an EU preference is risk averse/neutral/loving $\iff$ the utility function is concave/affine/convex.

- **Relative Risk Aversion**: measures attitudes towards lotteries that are proportional to wealth. The **coefficient** of RRA at wealth w is: $R(w) := -\frac{wu''(w)}{u'(w)}$. CARA utility has RRA: $R(w) = w(\alpha)$, which is increasing in w.

- CARA and CRRA are useful representations of EU preferences as they are linearly ordered by the "more risk averse than" relation.

- **Risk aversion and asset allocation**: investment is $\alpha$. If the return (Ez) is > 1, the optimal investment $\alpha$ is strictly positive. 

    - **Claim**: suppose $u_1$ is more risk averse than $u_2$ and that optimal investment levels $\alpha_1^\ast$ and $\alpha_2^\ast$ satisfy the FOC with equality. Then $\alpha_1^\ast \leq \alpha_2^\ast$. $\leftarrow$ the more risk-averse agent will invest less. 
    
    - **Pf**: WTS $U_2' (\alpha) \leq 0 \implies U_1'(\alpha) \leq 0$. It is sufficient to show that $U_2'(\alpha) \geq U_1'(\alpha)$ for all $\alpha \in [0,1]$. Follow the pf in L3S19.

- **Certain Equivalents**: solve U(w + CE(p)) = U(w + p) for CE(p), when all realizations of *x* under lottery *p* are near Ep = $\mu$. Intuition: what's the least you'd accept with 100\% certainty instead of taking 1/2 chance of winning 10000 and 1/2 of winning 0.

- **Insurance against a purely monetary loss**. Optimal purchase of actuarially fair insurance only *equates the marginal utility* in the various states. If the cost of insurance is higher than the probability of the loss, then you shouldn't buy it. 

- **Insurance with state dependent utility**: some accidents/illnesses can change utility at each wealth level(MWG63). 

- **Risk preferences of insurances in the lab**: Given the wealth of most lab subjects, they should be almost risk neutral to lab gambles(given they are small stakes), but they’re not.

- **First Order Stochastic Dominance**: let's say that for any $p \in \Delta (\mathbb{R})$, we let $F_p$ be its cumulative distribution function (c.d.f): $F_p(x) = Pr(z \leq x) = \int_{-\infty}^x p(x)dx$. Then we can say p ≥$^{FOSD}$ q, if $F_p(x) ≤ F_q(x)\forall x$. It doesn't necessarily let us compare the realization of lotteries but we could represent them with a perfectly correlated lottery where one is always as large as the other. We can define quantile functions for p,q and see how they relate in the sense: $F_p(x) \leq P_q(x) \forall x \iff x(\omega) \geq y(\omega) \forall \omega \in (0,1)$. 

**Theorem**: p ≥$^{FOSD}$ q $\iff \int u(dp) ≥ \int u(dq)$ for every weakly increasing function u: $\mathbb{R} \rightarrow \mathbb{R}$. *Intuition*: *p* FOSD *q* when *p* puts weakly more mass on higher values of *x* than *q*. Also said that *p* is *stochastically larger* than *q*. So we can say that $p \geq^{fosd} q \iff$ the expected utility from p exceeds that of q for every decision maker who prefers having more money than less. 

- **Second Order Stochastic Dominance**: what if we add **concavity**(risk-aversion) to the expected utility of lotteries? If the supports of *p* and *q* lie in [a,b]m we say *p* SOSD *q*, *p* $\succeq^{SOSD}$ *q* if $\int_a^c F_q(x)dx ≥ \int_a^c F_p(X) dx \forall c \in [a,b]$. 

**Theorem**: assuming expected values of p,q are equal $Ep$ = $Eq$, then $p \succeq^{SOSD} q \iff \forall$ nondecreasing concave $u$ on [a,b] $\int_b^a ud F_p ≥ \int_a^b udF_q$. **Intuition**: this comes from a related result, where $p SOSDs q$ only if we can write $p$ and $q$ as the marginal distributions of random variables $z_p$ and $z_q$ with $z_q = z_p + \epsilon$ and E($\epsilon | z_p$) ≤ 0. 

#### Proofs

- **FOSD**: p ≥$^{FOSD} q \iff \int u(dp) ≥ \int u(dq)$ for every weakly increasing function u: $\mathbb{R} \rightarrow \mathbb{R}$.

### **L4**

Readings for L4:

- Strzalecki 5.4, 5.6.1-5.6.4.

- Fehr-Duda and Epper(2012).

- Fehr-Duda, Bruhin et. al (2010).


#### **Non-EU Risk Preferences**

**Summary**: Non-EU Risk Preferences (Allais Paradox). When EU fails, what model should we use? Prospect Theory is great but violates FOSD. How to fix that? Calibrating Prospect Theory, Rank-Dependent EU.   

- **The Allais Paradox**: a set of alternatives can violate EU. See below an example of choice questions that violate expected utility. For more depth, see Strzalecki's notes. 

    - A: $1 \delta_1$ vs B $0.1 \delta_5 + 0.89 \delta_1 + 0.01 \delta_0$. Although expected utility is higher for B, considerably lot of people choose A.
    
    - C: $0.11\delta_1 + 0.89 \delta_0$ vs D: $0.1 \delta_5 + 0.9 \delta_0$. Again although EU of C is higher, a lot choose D.
    
    - Reason: use the independence axiom - $0.11 \delta_1 + 0.89 \delta_1 \succ 0.1 \delta_5 + 0.89 \delta_1 + 0.01 \delta_0 \rightarrow \delta_1 \succ (10/11)\delta_5 + (1/11)\delta_0$. 
    
Why do overweigh such small probabilities? Remember the Israelian buses example. 
    
- **Prospect Theory**: *intuition*: given that vN-M's EU's theory can be violated, KT came up with an alternative: Prospect Theory. By accomodating its 4 main ingredients: probability weighting, reference points, reflection effect and loss aversion, KT extended our analysis to a more realistic approach. Reference-dependent preferences for changes to current wealth (to accommodate ”loss aversion.”). Preference over lotteries non-linear in probabilities via probability weighting function. One critical problem is that the prospect theory allows violations of FOSD. This leads to rank-dependent expected utility and cumulative prospect theory.

The main idea is that instead of computing $\sum_z u(z)p(z)$ for each lottery p, the decision maker doesn't take the probabilities at their face value and instead transforms them somehow when computing the expected utility of p. The mapping p $\mapsto$ p' is called a **probability weighting function**:

- **Probability Weighting Function(aka Subjective Expected Utility)**: $\pi : [0,1] \rightarrow [0,1]$ is a PWF if $\pi$ is (weakly) increasing, continuous and $\pi (0)$ = 0 and $\pi (1)$ = 1.

**Naive probability weighting**: a preference on $\Delta (Z)$ has a NPW representation if there exists: i) a utility function $u: Z \rightarrow \mathbb{R}$; and ii) a PWF $\pi: [0,1] \rightarrow [0,1]$ such that the preference $\succeq$ is represented by: $U(p) = \sum\limits_{z \in Z} u(z) \pi (p(z))$. An example to illustrate this is given by Strzalecki 5.55. The example has one simple problem: it is a clear violation of FOSD monotonicity. 

Onto PT: assume the reference point r = 0, and to simplify consider lotteries $\ell$ with only 3 outcomes, all positive: 0 < $z_1$ < $z_2$ < $z_3$ with respective probabilities $p_1,p_2,p_3$. CPT says to set:

\[ U(\ell) = u(z_1) + \pi (p_2 + p_3)(u(z_2) - u(z_1)) + \pi (p_3)(u(z_3) - u(z_2)) \]

\[ [1 - \pi (p_2 + p_3)] u(z_1) + [\pi (p_2 + p_3) - \pi(p_3)] u(z_2) + \pi(p_3) u(z_3) \]

- Under EU, one way to compute expected utility is using **“vertical stripes”** as in Riemann integrals:

\[ EU = p_1 u (z_1) + ((p_2 + p_1) - p_1) u_2(z_2) + (1 - p_1 - p_2)u_3(z_3) \]

- Another way is using **"horizontal stripes"** as in Lebesgue integration:

\[ EU = u(z_1) + (1 - p_1)(u(z_2) - u(z_1)) + (1 - p_1 - p_2)(u(z_3) - u(z_2)) \]

CPT is like integrating the horizontal stripes, while replacing p with $\pi$(p); this gives preferences that respect FOSD. (Remember that if p $\geq^{fosd}$ q, p and q are the marginals of a pair of perfectly correlated lotteries with p always at least as large as q.) The slides proceed to present some examples from S14-SS19.

The failure of Prospect Theory to respect FOSD led to the development of:

- **Cumulative Prospect Theory**: *intuition*: although Prospect Theory was a great improvement, it need some refinements as it violated FOSD. For that, KT used ad-hoc functional forms:

\[ \pi(p) = \frac{p^\gamma}{(p^\gamma + (1 - p)^\gamma)^{1 / \gamma}}, \text{  } 0 < \gamma \leq 1\]

\begin{equation}
    u(z) =
    \begin{cases}
      z^\alpha, & \text{for z > 0} \\
      - \lambda (- z)^\alpha & \text{for z < 0}
    \end{cases}
\end{equation}

So now we divide outcomes and behaviors by positive and negative. For 0 < $\alpha$ < 1 the utility function is risk averse over gains and risk seeking over losses. The “kink” in utility at 0 allows for first-order effects of small gambles there; $\lambda$ > 1 says the decision maker is more sensitive to losses than gains.

The probability weighting function overweights extreme outcomes when their probabilities are low and underweights them when their probabilities are high—“S-shaped.” Decreasing $\gamma$ causes the weighting function to become more curved and to cross the diagonal farther to the right. Overweighting rare gains(lottery tickets) can make an "otherwise risk averse"($\alpha < 1$) agent risk seeking. Also, as $\uparrow \alpha \gets \to \downarrow$ risk aversion. Figure 5 reports. This allows an individual to be on unlikely gains and insure against unlikely losses. The papers presented in class illustrate further on CPT. One interesting application is regarding the **timing** of payoffs. 

- **Rank Dependent EU**: they are discontinuous as a given reward moves from below to above another.


### **L5**

Readings:

- Bernheim and Sprenger (2019).

- Strzalecki 7.1-7.6.

- MWG 6F.

#### **Subjective Probability and Subjected Expected Utility**

**Summary**: EU has failures that lead to PT, CPT and Rank-Dependent. Choice under **risk**. Choice under **uncertainty**. **Subjective** EU(Aumann). Mixture continuity. Monotonicity/Non-triviality/Independence. 

- CPT and Rank-Dependence Preferences are discontinuous: a given reward moves from below to above another. 

Start from defining: $\ell$: (p,q, 1 - p -q) on (x,y,z), x > y > z > 0. 

\[ U(\ell) = \pi(p) u(x) + [\pi (p + q) - \pi (p) ] u(y) + [\pi (1) - \pi (p + q)] u(z) \]

For m > 0, s.t. x > y + m, define the **lower equalizing reduction** $\underline{\rm k}$ that just offsets the increase in *y* with a decrease in *z*: 

\[ [ \pi (p + q) - \pi(p)] u(y + m) + [ \pi(1) - \pi (p + q)] u(z - \underline{\rm k}(m))	\]

$\underline{\rm k}$ does not depend on x. If we solve for it we get:

\[ \underline{\rm k} (m) = z - u^{-1} (u(z) - \frac{\pi (p+q) - \pi(p)}{1 - \pi(p+q)} [u( y + m) - u(y)])	\]

By holding fixed *p* of *x* and *q* of *y* but supposing x < y, again imagine increasing y and decreasing z. This defines the **upper equalizing reduction** $\overline{\rm k}$, after some manipulation:

\[ \overline{\rm k}	= z - u^{-1} (u(z) - \frac{\pi (q)}{1 - \pi (p+q)} [u(y + m) - u(y)]) \] 

This second equalizing reduction also doesn't depend on x but its value is different: it's double according to KT(1992). CPT predicts that the compensating reduction in z doesn't depend on x except when *x switches from less than y to greater than y*.

- Bernheim-Sprenger focuses on the usual parametric CPT specification, but Proposition 1 gives a non-parametric version of this: Any given probability weighting function makes quantitative predictions about the size of the jump in compensating reduction when x moves from above y to below y. Here there is no "jump".

**Conclusion**: in the search for a good theory of choice under uncertainty, we should account for:

1) the inverse S-shaped certainty equivalent profile.

2) the absence of rank-dependence in equalizing reductions.

3) the sharp drop in certainty equivalents that results from splitting an event. 

- EU fails 1,3. CPT fails 2,3. PT fails 3.

##### **Intermission**

So far in the course we have seen that:

- **EU** has failures.

- **CPT** with an S-shaped probability weight curve fits many experiments and is the second-most-used (after EU) theory of risk preferences both in economics and finance. Still, it has failures.

- Is it possible to find a better model than "PT + complexity aversion"? How can we formalize complexity aversion so it can be tested.

- Empirical applications of PT/CPT that don't rely on rank dependence are safer frm this critique but still susceptible to criticism.

##### **Subjective Probability and Subjected Expected Utility**

- Choice under risk: randomness in consequences but known probabilities. Risk is quantifiable.

- Choice under uncertainty: some/all probabilities are unknown. 

- **Subjective expected utility**: EU but where the probabilities **p represent subjective belief**. Famous: Savage(in Strzalecki's notes) and Anscombe-Aumann. Building on AA(1952): some p objectively known, only finitely many subjective states $\rightarrow$ we can calibrate the subjective probabilities to the objective ones.

- Z: finite set of outcomes that agent cares about.

- S: finite state space - contingencies that partially determine outcomes.

- $\mathcal{F}$:= $(\Delta (Z))^S$, all acts. 

- $f$: an act that informs what probability distribution on outcomes we get for each state. 

- **Act** + probability distribution on **s** = distribution on outcomes.

- An act $f \in \mathcal{F}$ gives the objective lottery f(s) for each s. E.g. “If the Patriots win next year’s Super Bowl, roll a die and get $100 if it comes up 1, 2 or 3.”

**Intuition**: The idea is that the decision maker has a subjective probability distribution on the states in *S*. An act says what probability distribution on outcomes they get for each state, so an act combined with a probability distribution on states gives a distribution on outcomes. By writing the set of acts as $\mathcal := (\Delta (Z))^S$ assumes that every outcome is possible in every state. If there are distinct outcomes for each state, we write $Z_s$ and can't separately identify the agent's utility function and their beliefs.

- For $\alpha \in [0,1]$ and f,g $\in \mathcal{F}$, the **mixture** of the acts in the form of $\alpha f + (1 - \alpha)g$ is the act that for each state *s* gives the lottery: $\alpha f(s) + (1 - \alpha)g(s) \in \Delta (Z)$.

- We identify lotteries over all acts $\mathcal{F}$ with their mixture $\rightarrow$ we identify **compound lotteries**. For example: suppose we have 2 states (S=2). We are saying that $\frac{1}{2}(a,a)$ + $\frac{1}{2}(b,b)$ is the same as $\frac{1}{2}(a,b) + \frac{1}{2}(b,a)$ because both reduce to the same point in $\mathcal{F}$ $\rightarrow$ different mixture, same lottery.

- What if the decision-maker cares about what he would've gotten in another state that didn't happen? For ex: getting *a* in S=1 depends on what what they would've gotten in S=2. This leads to:

\[ dim(\mathcal{F}) = dim (\Delta (Z)^S) = \#S (\# Z - 1) \leq \# S \# Z - 1 = dim(\Delta (Z^S)) \]

For example: given S=2 and Z=3: $dim (\mathcal{F}) = 2 \times 2 = 4$, while $dim(\Delta (Z^S)) = 5$.

##### **Goals**

We want to characterize when a complete transitive preference on the set of all acts $\mathcal{F}$ has a subjective expected utility representation of the form:

\[ V(f) = \sum_{s \in S} u(f(s))p(s)\]

Understand the extent to which *u*(utility) and *p*(subjective probability distribution) are pinned down. It's important that the utility function **doesn't depend on the state**. If the utility function depends on the state then for any *q* with full support we have:

\[ V(f) = \sum\limits_{s \in S} (u_s (f(s)) \frac{p(s)}{q(s)})q(s)\]

representing the same preferences. For more on this, see Strzalecki's 7.1. To obtain the Subjective EU representation, we need the following axioms:

- **Axiom: Mixture continuity**: $\forall f,g,h \in \mathcal{F}$, the sets: 

\[ \{ \alpha \in [0,1]: \alpha f + (1 - \alpha)g \succeq h \} \]

and

\[ \{ \alpha \in [0,1]: \alpha f + (1 - \alpha)g \preceq h \} \]

are closed in [0,1].

- **Constant acts**: a preference on acts leads to a preference on lotteries (constant acts). For z $\in$ Z or p $\in \Delta (Z)$, let $\overrightarrow{\rm z}$ and $\overrightarrow{\rm p}$ denote the **constant acts** that give $\delta_z$ or *p* in every state. Any preference on the space of state-contingent acts $\mathcal{F} := (\Delta (Z))^S$ induces a preference on constant acts: for p,q $\in \Delta (Z)$ say that p $\succeq$ q $\iff$ $\overrightarrow{\rm p} \succeq \overrightarrow{\rm q}$.

- **Axiom: Monotonicity**: if an act f(s) $\succeq$ g(s) for all $s \in S$, then we can say that f $\succeq$ g. If $\overrightarrow{\rm f(s)} \succeq \overrightarrow{\rm g(s)} \forall s$, then f $\succeq$ g. Implicitly assumes it is state-independent(slide 17, L5).

- **Axiom: Non-triviality**: $\exists$ *f*, *g* $\in \mathcal{F}$ such that $f \succ g$. $f \sim g$ would be trivial.

- **Axiom: Independence**: $\forall f,g,h \in \mathcal{F}$ and $\alpha \in (0,1)$:

\[ f \succeq g \iff \alpha f + (1 - \alpha)h \succeq \alpha g + (1 - \alpha) h \]

Similar to independence but this is on a larger space. Independence + Monotonicity $\implies$ the independence axiom for objective risks but it adds additional restrictions. 

#### **Anscombe and Aumann 1952 Theorem**

- A complete transitive preference $\succeq$ on $\mathcal{F}$ satisfies mixture continuity, monotonicity, non-triviality and independence $\iff$ there is a non-constant linear u: $\Delta (Z) \rightarrow \mathbb{R}$ and a *p* $\in \Delta(S)$ s.t. V(f) = $\sum_s u(f(s))p(s)$ represents $\succeq$. Moreover, p is unique and u is unique up to affine transformations. 

- **Intuition: calibrate subjective probabilities to objective ones.**

Suppose x,y $\in Z, \overrightarrow{\rm x} \succ \overrightarrow{\rm y}$.For each E $\in 2^S$, find the $\alpha$ s.t. $\alpha \overrightarrow{\rm x}$ + (1 - $\alpha$) $\overrightarrow{\rm y}$ $\sim$ $\overrightarrow{\rm x_Ey}$, where $\overrightarrow{\rm x_Ey}$ means the **act that pays x for s** $in E$ and **y for s** $\in S- E$. Upon finding it, it is our candidate for p(E). WTS that p(E) doesn't depend on the choice of x,y $\in Z$ and that *p* is a probability distribution. 

**Proof**: the goal is to characterize when a complete transitive preference on $\mathcal{F}$ has a subjective expected utility representation of the form V($f$) = $\sum_s u(f(s))p(s)$. And understand the extent to which *u* and *p* are pinned down. 

1) The induced preference on $\Delta(Z)$ satisfies vN-M axioms $\rightarrow$ it is represented by a non-trivial utility function *u* that is linear in the objective probabilities. 

2) Normalize the range of *u* to be *U* = [-1,1]. Let's define a **utility act** in a way that in each state *s* get lottery with vN-M utility *u*: map $\tau$: S $\rightarrow$ U. Then the space of all utility acts is $U^S$. Define $\succeq^\ast$ on $U^S$ by $\tau \succeq^\ast \tau'$ $\iff$ $f \succeq g$ for some $f,g \in \mathcal{F}$ s.t. $\tau = u \circ f$ and $\tau' = u \circ g$.

3) **Claim**: from monotonicity we know that $\succeq^\ast$ doesn't depend on the choice of $f,g$ so it's a complete transitive preference. **Proof**: to show $\succeq^\ast$ doesn't depend on the choice of $f,g$: 
    
    a) Suppose $\exists f,f',g,g' \in \mathcal{F}$ s.t. $\tau = u \circ f = u \circ f'$ and $\tau' = u \circ g = u \circ g'$. 
    
    b) Then, $\forall s$, u(f(s)) = u(f'(s)), so f(s) $\sim$ f'(s), and from monotonicity: $\overrightarrow{\rm f(s)} \sim \overrightarrow{\rm f'(s)}$ for all s. So(using monotonicity again) f $\sim$ f'.
    
    c) Similarly g $\sim$ g'.
    
    d) Thus: f $\succeq$ g $\iff$ f' $\succeq$ g' $\iff$ $\tau \succeq^\ast \tau'$. 

4) Let I($\tau$) $\in$ [-1,1] for "indifference" be the **number s.t. the constant utility act** $\overrightarrow{\rm I(\tau)}$ **is indifferent to** $\tau$. I($\tau$) will end up being the expected utility of $\tau$ in our representation, but first we have to how I($\tau$) is well defined. **Claim**: I($\tau$) exists and is unique. Sketch:

    a) define upper and lower contour sets: $U(\tau) = \{ \eta \in [-1,1]: \overrightarrow{\rm \eta} \succeq \tau \}$ and L($\tau$) = \{ $\eta \in [-1,1] : \overrightarrow{\rm \eta} \preceq \tau \}$.
    
    b) These sets are non-empty, closed (from mixture continuity) and their union is [-1,1], so they have a non-empty intersection.
    
    c) From the definition of utility acts, this intersection is unique (otherwise $u > u'$ and (u,u,...,u) $\sim$ (u',u',...,u'))
    
    d) Define the intersection to be I($\tau$).
    
    e) note that by construction $\tau \succeq^\ast \sigma \iff I(\tau) \geq I(\sigma)$, so I represents $\succeq^\ast$. 

5) Use independence to show that $I(\lambda \tau)$ = $\lambda I(\tau)$. We do this in three steps:

    a) First we do this for $\lambda \in (0,1)$: 
    
      - Fix any $\tau \in U^S$, and any $f \in \mathcal{F}$ s.t. $\tau = u \circ f$.
      
      - Pick p,q $\in \Delta(Z)$ s.t. u(p) = I($\tau$) and u(q) = 0.
      
      - Then $f \sim \overrightarrow{\rm p}$, so by independence: $\lambda f + (1 - \lambda) \overrightarrow{\rm q} \sim \lambda \overrightarrow{\rm p} + (1 - \lambda) \overrightarrow{\rm q} = \overrightarrow{\rm (\lambda p + (1 - \lambda)q)}$

      - So $\lambda \tau \sim^\ast \overrightarrow{\rm \lambda I(\tau)}$ and thus $I(\lambda \tau)$ = I $\overrightarrow{\rm (\lambda I (\tau))} = \lambda I (\tau)$ (because I(u,u,...,u) = u).
      
    b) For $\lambda > 1$ and $\lambda \tau \in U^S$ start with $\lambda \tau$ and multiply by $\frac{1}{\lambda}$.
    
    c) Then extend $I$ to all of $\mathbb{R}^S$ by setting $I(\tau)$ = $||\tau||_1 I(\frac{\tau}{||\tau||_1})$. We took U = [-1,1] instead of U = [0,1] so we could do this. 
      
6) Similarly show *I* is additive, that is that:

\[ I(\lambda \tau + (1 - \lambda)\sigma) = \lambda I(\tau) + (1 - \lambda) I(\sigma) \]

7) Given *I* is a linear operator on $\mathbb{R}^S$ $\implies$ there is a unique vector *p* s.t. I($\tau$) = $\sum_s p(s) \tau(s)$.

8) This *p* is a probability distribution, i.e., each entry non-negative and sums to 1.

9) Set V(f) - $\sum_s u(f(s))p(s)$.

- **Eliciting Subjective Beliefs**: rather win \$ 10 for sure if Event *E* happnes or with probability *p* = (0.1, 0.2, ..., 1). Pick a probability *q* at random and give her the choice she selected. 

- **Proper scoring rule**: ask the agent to report the vector *p* and pay them (in cash) z(p,s). z is a proper scoring rule if for any belief *p*: $p \in arg max_{q \in \Delta (S)} \sum\limits_{s \in S} p(s) z(q,s)$.

- Subjective probability is **purely subjective**: it doesn't need to correspond to any objective randomness because you can have subjective beliefs about knowable facts that you don't happen to know.

- **Confidence intervals exercise**.

### **L6**

Readings for L6:

- Strzalecki 7.5, 10.3-5.

- Halevy (2007).

Optional papers:

- Alpert and Raiffa (1982).

- Biais et al. (2005).

- Berner and Graber (2008).

- Camerer and Weber (1992).

- Trautmann and Van De Kuilen (2015).

#### **Confidence Intervals!**

**Summary**: relating the confidence interval experiment to subjective expected utility. Ambiguity. Maxmin preferences (axioms: Certainty Independence and Uncertainty Aversion). Convex Analysis. Variational Preferences.

- People are overconfident on their confidence intervals. They could benefit from feedback as it leads to better calibration. Also possible to recalibrate on repetitive events. 

- **Ellsberg Paradox**: 90 balls in an urn composed of red, black and green balls. 30 of the balls are definitely red; the other 60 could each be black or green. S = \{ R,G,B \}, 4 acts f,g,f',g' that pay \$x or \$0. The example given(see slides) is not consistent with subjective EU as f$\succeq$g $\implies$ $\mathbb{P}(R) > \mathbb{P}(G)$ and g'$\succeq$f' $\implies$ $\mathbb{P}(R) < \mathbb{P}(G)$

- Related thought experiment of Keynes(1921). 

- The problems of the last two examples arise because of **ambiguity**. Say that someone is “ambiguity averse” if they prefer the objective lottery to the subjective ones as in Keynes’ example.

- This violates independence! In response, various models of ambiguity averse preferences relax the independence axiom. An example of a model would be the **maxmin preferences**:

- **Maxmin preferences [Gilboa and Schmeidler, 1989]**: start from the Anscombe and Aumann setup. As before, take S finite and let $\mathcal{F} = (\Delta (Z))^S$ be the space of acts that give one objective lottery per state. Drop the independence axiom, replace it with **certainty independence** and **uncertainty aversion**.

    - **Certainty Independence**: for all constant acts $\overrightarrow{\rm AB \ell}$ and all f,g $\in \mathcal{F}$, f $\succeq$ g $\iff$ $\alpha f + (1 - \alpha) \overrightarrow{\rm AB \ell} \succeq \alpha g + (1 - \alpha) \overrightarrow{\rm AB \ell}$ for all $\alpha \in (0,1)$. This is **weaker than independence**, which states that the equation holds for *any* act(instead of $\overrightarrow{\rm AB \ell}$) and all $\alpha$. 
    
    - **Uncertainty Aversion**: whenever $f \sim g$, $\alpha f + (1 - \alpha)g \succeq f$ for all $\alpha \in (0,1)$ (preference for hedging). Given states R,B: $f$ pays 1 in R and 0 in B; $g$ is the opposite: pays 0 in R and 1 in B. Then $\alpha f + (1 - \alpha) g$ pays ($\alpha, (1 - \alpha)$) so "less uncertain", $\alpha$ = 1/2 pays EU = 1/2 regardless of state.
    
By assuming the above, we arrive at GS1989's theorem:

- **Theorem (Gilboa and Schmeidler [1989])**: Complete transitive preferences on $\mathcal{F}$ satisfy mixture continuity, monotonicity, non-triviality, certainty independence, and  uncertainty aversion iff there is a linear, non-constant $u: \Delta (Z) \rightarrow \mathbb{R}$ and a non-empty, closed, convex set of distributions $C \in \Delta (S)$ s.t. 

\[ V(f) := \min\limits_{p \in C} \sum\limits_{s \in S} p(s)u(f(s))\]

Moreover, C is identified uniquely, and *u* is unique up to affine transformation. This representation has a pessimistic agent: with C as priors, the agent tries to maximize the worst possible payoff. This allows the Ellsberg choices. 

- **Proofs**....

#### **Convex Anaysis**

- The representation theorem uses **support functions**:

**Definition:** for closed, convex and non-empty C $\subseteq$ $\mathbb{R}^{\# S}$, the support function $R_C: \mathbb{R}^{\# S} \rightarrow \mathbb{R}$ is

\[ R_C(\tau) := \inf\limits_{p \in C} \sum\limits_{S} p(s) \tau(s) \]

Where in the maxmin representation, **C is the set of priors**.

Functions *I* with the properties we established above can be identified with a unique closed, convex set C $\in \Delta (S)$ s.t. I($\tau$) := $min_{p \in C} \sum_S$ p(s)$\tau$(s). With maxmin preferences, it only matters whether a probability distribution *p* is in or out of the support.

- **Variational Preferences**: MMR(2006) $V(f) = \min\limits_{p \in \Delta (S)} \sum\limits_{s \in S} p(s)u(f(s)) + c(p)$, where C : $\Delta (X) \rightarrow [0,\infty]$ is convex, lower semi-continuous, and satisfies c(p) = 0 for at least one *p*. It uses the same axioms as maxmin but with *weak certainty independence* replacing independence. The proof uses a more general result about convex duality.

Functions *I*

### **L7**

Readings for L7:

- Strzalecki 2.

- Kreps (1979).

#### **Deterministic Dynamic Choice**

**Summary**: dealing with multiperiod choices. Consequentialism. History-dependent. Recursively Consistent Representation(DCC). Dynamically stable. Temptation + Self Control. Strotz Representation. (Naive)Quasi-hyperbolic agents. Control costs.

The setting is: 

- Two periods: t=0 and t=1.

- Spaces $Z_0,Z_1$ of outcomes.

- t=0 choice: $X_0 := Z_0 \times M(Z_1)$ (M(Z) = $2^Z - \{ \varnothing \}$).

- t=1 choice: $X_1 := Z_1$.

- Example: Initial wealth: $w_0$. Can spend some but not borrow; can save at real rate *r*. So period-0 menu is:

\[ \{ (c_0, m(c_0)): c_0 \in [0,w_0], m(c_0) = [0,(1 +r) (w_0 - c_0)] \} \]

- **Choices and Histories**: usually period-0 choices are described by a choice correspondence:

\[ c_0 : M(X_0) \rightarrow M(X_0) \text{ s.t. } \underbrace{c_o(A_0)}_{\text{finite collection of pairs}} \subseteq A_0 \forall A_0 \in M(X_0) \]

Here, $c_0(A_0)$ is a finite collection of pairs $\{ (z_0', A_1'), (z_0'', A_1''),...\}$. Choices in t=1 might depend on t=0 consumption. Initially we let they also depend on the choice problem the agent faced in t=0. So we define the t=0 histories $h_0$ as pairs ($A_0, x_0$) where $A_0$ is the menu the agent faced, and $x_0$ is the choice made. The set of all possible period-0 histories is then:

\[ H_0 := \{ (A_0,x_0) \in M(X_0) \times X_0 : x_0 \in c_0 (A_0) \} \]

- The **domain of the choice correspondence** at t=1 is the current menu $A_1$ and the history that preceded it. Denote this as

$\mathcal{D}_1 := \{ (A_1, A_0, x_0) \in M(X_1) \times H_0 : (A_0, x_0) \in H_0(A_1) \}$

- The t=1 choice correspondence is a:

\[ c_1 : \mathcal{D}_1 \rightarrow M(X_1) \text{ with } c_1(A_1,A_0,x_0) \subseteq A_1 \]

- A **dynamic choice correspondence** is a pair ($c_0, c_1$) that satisfies 1 and 2.

- **Consequentialism**: what you order at dinner (t=1) can depend on $z_0$. However, it requires that what you order at dinner in an Italian restaurant doesn't depend on whether the alternative restaurant you considered was Greek or Spanish. It is a form of "no regret" condition. **Definition**: a dynamic choice correspondence is *consequentialist* if $c_1(A_1,A_0,x_0) = c_1(A_1,B_0,x_0)$ for all $A_1 \in M(X_1)$ and all $(A_0,x_0), (B_0,x_0) \in H_0(A_1)$. This requires that the agent makes the same choice from $A_1$ regardless of the period-0 menu $A_0$ or $B_0$. The "s.t." part says to only look at situations where the period-0 menu allows picking $x_0$. From here on we assume consequentialism and write $c_1 (A_1, x_0)$. 

- **History-independent**: $c_1 (A_1, z_0) = c_1 (A_1, z_0')$ $\forall$ $z_0, z_0' \in Z$, $A_1 \in M(X_1)$. Will assume history independence (aka time-separability) for the rest of the lecture and denote t=1 choice as $c_1(A_1)$.

- Let's take one step further: there's no consumption at t=0. Set: $X_0 = M(Z_1)$. Assume both $c_0,c_1$ satisfy WARP.

- They correspond to maximizing complete transitive preferences $\succeq_0$ and $\succeq_1$ and maximizing utility functions $u_0$ and $u_1$. 

- **Recursively Consistent Representation (DCC)**: preferences ($\succeq_0 , \succeq_1$) have a RCR/DCC if they can be represented by $u_0,u_1$ s.t. $u_0(A_1) = max_{z_1 \in A_1} u_1 (z_1)$. **Definition**: period-0 preference $\succeq_0$ is *strategically rational* if $A_1 \succeq_0 B_1 \implies A_1 \sim_0 A_1 \cup B_1$. However, there can exist an "option value" such that $A_1 \preceq_0 A_1 \cup B_1$. 

- **Lemma** (Kreps 1979): t=0 preference $\succeq_0$ is **strategically rational** $\iff$ the function $u_0$($A_1$) = $max_{z_1 \in A_1}$ $u_0 (\{z_1\})$ represents $\succeq_0$. Proof sketch follows. 

- **Dynamically stable** preferences are when the answer to the preferences are the same at t=0, t=1:

\[ \{ z_1 \} \succeq_0 \{ w_1 \} \iff z_1 \succeq_1 w_1 \]

- **Theorem for RCC**: preferences ($\succeq_0, \succeq_1$) are RCR $\iff$ they are strategically rational and dynamically stable. RC rules out stochastic period-1 preferences. To allow stochastic preferences, Kreps uses the following representation:

\[ u_0(A_1) = \sum\limits_{s \in S} p(s) [ \max\limits_{a_1 \in A_1} u_1 (a_1, s)] \text{ for some S,p and }u_1 \]

Where $u_1$ can depend on s. But neither $u_1$ nor $p$ can depend on $A_1$. Using this representation, if \{a,b\} $\sim_0$ \{ a \} then the agent can never strictly prefer b in a menu that contains a. More generally, this representation satisfies **modularity**: 

\[ \text{If } A_1 \sim_0 A_1 \cup B_1 \text{, then } A_1 \cup C_1 \sim_0 A_1 \cup C_1 \cup B_1 \]

- **Preference for Flexibility**: if $A_1 \supseteq B_1$ then $A_1 \succeq_0 B_1$. Drew calls this monotonicity.

##### **Temptation and Self Control**

- A strategically rational agent would never strictly prefer a smaller menu, and wouldn’t sign up for a monitoring program that has only fines and no positive payments.

- **Strotz Representation**: whenever t=0 preference $\succeq_0$ has $u_0,u_1$ such that:

\[ c_1 (A_1) = arg \max\limits_{z_1 \in A_1} u_1 (z_1) \text{ and } c_0(A_0) = arg \max\limits_{A_1 \in A_0} ( \max\limits_{z_1 \in c(A_1)} u_0 (z_1)) \]

- The individual knows his preferences will change: it's as if an equilibria between two selves.

- **No Compromise**: t=0 preference $\succeq_0$ satisfies **no compromise** if $\forall$ $A_1, B_1 \in M(Z_1)$ either $A_1 \sim_0 A_1 \cup B_1$ or $B_1 \sim_0 A_1 \cup B_1$. 

- Gul and Pesendorfer Theorem (2005): $\succeq_0$ satisfies *no compromise* if it has a Strotz representation. The Strotz representation is closely related to quasi-hyperbolic discounting, where preferences are represented by

\[ U_0 = u_0 + \beta \delta u_1 + \beta \delta^2 u_2 \text{ and } U_1 = u_1 + \beta \delta u_2 \]

Here the t=1 utility function $U_1$ differs from t=0 utility $U_0$ in its tradeoffs between immediate rewards in period 1 and rewards that will arrive later, say in a period 2 where the agent has no decision to make. The idea is that the t=1 agent will sacrifice period 2 consumption for consumption in t=1 at worse terms than the t=0 agent would like.

- **Quasi-hyperbolic agents** only care about the actions they (think they will) take, no cost of resisting temptations that don’t alter eventual choices.

- **Sophisticated quasi-hyperbolic** agents correctly forecast their future actions, as in Strotz.

- **Naive quasi-hyperbolic** agents forecast that their future actions will be the ones they "would like them to take". 
- Gul and Pesendorfer [2001]: Assume complete transitive preferences on the set $\mathcal{A}$: all compact subsets of $\Delta (Z)$. In period 0 the agent chooses a menu of lotteries from a menu of (compact) lottery menus, i.e. $X_0$ := $M(\mathcal{A})$. Characterize the “self control” representation:

\[ u_0 (A_1) = \max\limits_{z_1 \in A_1} (u_1 (z_1) - (\max\limits_{x_1 \in A_1} v_1 (x_1) - v_1(z_1))  \]

\[ = \max\limits_{z_1 \in A_1} (u_1 (z_1) + v_1(z_1) - \max\limits_{x_1 \in A_1} v_1 (x_1)) \]

- Here $u_0,u_1,v_1$ are all vN-M expected utility functions. $v_1$ is a "temptation function", and the control cost of choosing $z_1$ from menu $A_1$ is the resisted temptation ($max_{z_1' \in A_1} v_1(z_1') - v_1(z_1)$). 

- **Set betweenness**: $A_1 \succeq_0 B_1 \implies A_1 \succeq_0 A_1 \cup B_1 \succeq_0 B_1$. In the GP representation only the **biggest** temptation in *A* matters. **Control Cost**  in GP is linear in foregone utility, represented by $\max\limits_{z_1' \in A_1} v_1(z_1') - v_1(z_1)$. The GP independence axiom is the combination of the usual independence axiom on outcomes and the assumption that the agent makes the same choice before or after the uncertainty is resolved. The model on t=1 choice by GP is:

\[ c_1(A_1) = arg max_{z_1 \in A_1} (u_1 (z_1) - (max_{x_1 \in A_1} v_1 (x_1) - v_1(z_1)))\]

\[ = argmax_{z_1 \in A_1} u_1(z_1) + v_1(z_1)\]

Note that *c* doesn't depend on the $max_{x_1 \in A_1} v_1 (x_1)$.

- Fudenberg and Levine(2006) dual selves model: doer(interacts with the world) and planner. LR self maximizes, achieves subgame-perfect equilibrium.. The control cost depends on the foregone utility but not other items in the menu.

- **Convex control costs** allow certain (but not all!) violations of WARP, such as a sort of ‘compromise effect”: Choose fruit from (fruit, small dessert) but small desert from (fruit, small dessert, large dessert), because the presence of the large dessert makes settling for fruit much more costly. Convex costs explain why more self-indulgent in one domain (e.g. diet or exercise) when exerting more self control in another (e.g. hours of work).

### **L8**

Readings:

- Strzalecki 3.1-3.3, 4.

**Summary**: 2nd lecture on multi-period. Discounting; Finite vs infinite horizon.  

- **Exponential discounting**: when dealing with choice over time, most economic models use exponential discounting: $U(x_0,x_1,...) = \sum\limits_{t} \delta^t u(x_t)$. Here, the agent has the same history-independent utility function *u* for every period and the **constant discount factor** $\delta$. 

- **Expected discounted utility**: combines discounting with risk. This links risk aversion with a preference for consumption smoothing. EDU implies that the agent's preferences respect Bayes law and the rules of conditional probability. 

- **Separable preferences**: discounting representation implies that preferences are **additively separable** over time. Let *I* be a finite set of indices (time periods, fruits, states). $\forall i \in I$ there is a set $X_i$, let X:= $x_{i \in I} X_i$. Analyst observes complete transitive preference $\succeq$ on $X$. 

    - **Definition**: $\succeq$ has an additively separable representation if there are $u_i$: $X_i \rightarrow \mathbb{R}$ s.t. $U(x_1, ..., x_n) = u_1 (x_1) + ... + u_n (x_n)$ respresents $\succeq$. 
    
- In an additively separable representation, the tradeoff between $x_i$ and $x_j$ is independent of other components, i.e., of $x_{-ij}$. It is also possible for a preference to have a preference that is additively separable and another that isn't. For ex: $U(x_1,x_2) = x_1 x_2$ isn't additively separable, but $ln U = ln x_1 + ln x_2$ is, and these represent the same preferences. For any $E \subseteq I$(that is a subset of the finite set of indices) and any $x,y, \in X$ define

\begin{equation}
    x_Ey \in X :=
    \begin{cases}
      x_i & i \in E \\
      y_i & i \notin E
    \end{cases}
\end{equation}

**Definition**: $\succeq$ is **singleton separable** if for all $i \in I$ and all x,y,z,z' $\in$, $x_iz \succeq y_i z \iff x_i z' \succeq y_i z'$. Singleton separability is necessary but not sufficient for an additively separable representation. SS implies that for each index *i* we have a complete transitive preference $\succeq_i$ on $X_i$ that is independent of the other components: $x_i \succeq_i y_i$ if $x_i z \succeq y_i z$ for some *z*. We have to use a stronger condition:

- **Thomsen Condition**: $\forall x,y,z \in X$, ($x_1, y_2$) $\sim$ ($y_1,x_2$) and ($y_1, z_2$) $\sim$ ($z_1, y_2$) implies that $(x_1,z_2) \sim (z_1, x_2)$. When there are 3 or more indices, additive separability requires that the tradeoff between $x_i$ and $x_j$ doesn't depend on the level of some 3rd index *k*. $\succeq$ has **jointly separable indices** if for any $E \subseteq I$ and all x,y,z,z' $\in X$, $x_E z \succeq y_E z$ $\iff$ $x_E z' \succeq y_E z'$ (Strzalecki cals this "separable"). For joint separability to have any bite we need 3 indices that "matter" because with only two it simply reduces to singleton separability. 

- **Null Index Definition**: an index *i* is *null* if $\forall x,y,z \in X, x_i z \sim y_iz$. By asking that at least three indices be non-null + that each $X_i$ corresponding to a non-null index be **connected** = each non-null coordinate has a continuum of elements. Since **additively separable representations have a utility function**, we expect to need a **continuity** condition when X isn't finite. **Technical condition**: assume each $X_i$ is a connected subset of $\mathbb{R}^k$ and that $\succeq$ on X:= $x_{i \in I} X_i$ is continuous w.r.t the product topology. 

- **Theorem (Debreu 1960 + Wakker 1988)**: suppose complete transitive $\succeq$ satisfies the technical condition and has at least three non-null indices $\rightarrow$ it has *jointly separable indices* $\iff$ it has an additively separable representation by continuous utility functions $u_i$: $X_i \rightarrow \mathbb{R}$ s.t. $u_i$ is constant whenever $i$ is null. Moreover, if $v_1,...,v_n$ also represent $\succeq$, then there are $\alpha > 0$ and $\beta_i$ s.t. $v_i = \alpha u_i + \beta_i$. Proof: we're free.

##### **Finite Horizon Consumption Streams**

- **Finite horizon case**: $t \in \tau := \{ 0,1,..., T \}$ for some T > 1. Assume that $\mathcal{X} = X^{T+1}$ where $X$ is a connected subset of $\mathbb{R}^n$ and $\mathcal{X}$ has the product topology. Debreu's theorem yields an additively separable representation, but the representation $U(x_0,x_1,...) = \sum_t \delta^t u(x_t)$ needs *more assumptions* to get the same function *u* in every period and a constant discount factor. 

- **Stationary Definition**: $\succeq$ on $\mathcal{X}$ is *stationary* if $\forall c \in X$, $x,y \in X^T$ $(c, x_0, ...., x_{T-1}) \succeq (c, y_0, ..., y_{T-1})$ $\iff$ ($x_0,...,x_{T-1},c) \succeq (y_0, ..., y_{T-1},c)$. 

- **Sensitive Definition**: $\succeq$ on $\mathcal{X}$ is *sensitive* if all of the indices are non-null. 

**Theorem(Fishburn 1970)**: complete transitive preference $\succeq$ on $\mathcal{X}$ := $X^{T+1}$ is continuous, stationary, sensitive and has jointly separable indices $\iff$ there is a number $\delta > 0$ and a continuous non-constant function $u$: $X \rightarrow \mathbb{R}$ s.t. $\succeq$ is represented by $U(x_0, x_1,...)$ = $\sum_t \delta^t u (x_t)$. Moreover, $\delta$ is unique and u is unique up to affine transformations. In the proof sketch, we arrive at $v_t = \delta^t u$. To interpret this $\delta$:

- **Interpreting** $\delta$: can be <, = or > than 1: the agent could care **more** about periods in the future. $\delta < 1$ can be seen as either prefering utility now to later or as uncertainty that the current consumption stream will continue. $\delta$ = 1 gives the time average criterion: $U(x_0,x_1,..., x_T) = \sum_{t=0}^T \frac{u(x_t)}{(T+1)}$. Depending on the setting, it is possible for $\delta$ to depend on the **period length** $\Delta$ according to $\delta = exp(-\rho \Delta)$. It is possible to have $\delta = 0$, but that means completely ignoring the future.

##### **Infinite Horizon Consumption SerieS**

- **Infinite Horizon Case**: let $T = \{ 0,1,... \}, \mathcal{X} = X^{\infty}$. Setting: the representation $U(x_0,x_1,...) = \sum\limits_{t=0}\limits^{\infty} \delta^t u(x_t)$ again needs joint separability, and versions of stationarity, non-null indices and continuity. What differs from finite horizon: possibility that the discounted sum diverges and apparently technical conditions like continuity can have more substantive impact that you might have expected. It is harder to say what we mean by **"complete patience"** or "time neutrality": as $lim_{T \rightarrow \infty} \sum\limits_{t = 0}\limits^{T} \frac{u(x_t)}{(T+1)}$ need not exist. Two alternative "complete patient" criteria: 

  - **Time averaging**: $\lim \inf\limits_{T \rightarrow \infty} \sum\limits_{t=0}^T \frac{u(x_t)}{(T+1)}$. This is a very "weak" preference: many sequences are indifferent to each other.
  
  - **Overtaking criterion**: $x \succ x'$ if $\lim \inf\limits_{T \rightarrow \infty} \sum_{t = 0}^T [x_t - x_t'] > 0$. This is not a complete order: **a sequence whose partial sums converge to 0 while alternating sign is not comparable to** $\overrightarrow{\rm 0}$(constant 0).
  
- **Stationary Preferences**: $\succeq$ is *stationary* if $\forall c \in X$, $x,y \in X^{\infty}$, ($x_0,x_1,...) \succeq (y_0,y_1,...) \iff (c,x_0,x_1,...) \succeq (c,y_0,y_1,...)$. 

- **Sensitive Preferences**: $\succeq$ is *sensitive* to the initial period if index 0 is non-null.

If we assume $X = \mathbb{R}$ and set u(x) = x, time averaging is not sensitive to the initial period, the overtaking criterion is. 

- **Initially separable**: $\succeq$ on $\mathcal{X}$ is initially separable if $\forall$ a,b,c,d $\in X$ and x,y $\in X^{\infty}$, ab*x* $\succeq$ cd*x* $\iff$ ab*y* $\succeq$ cd*y*. *Intuition: the tradeoff between the first two periods doesn't depend on what comes afterwards*. (if $\succeq$ on $\mathcal{X}$ is *stationary*, then it is sensitive and jointly separable $\iff$ it is sensitive to the initial period and initially separable)

- **Constant Equivalence**: $\succeq$ satisfies *CE* if for any $x \in X^{\infty}$ there is a $c \in X$ s.t. $x \sim (c,c...) := \overrightarrow{\rm c}$. (this jointly constraints the set *X* and how agent feels about "tail consumption" as $x$ = (1,2,4...) might be better than any constant path.

- **Tail continuous**: $\succeq$ is *TC* if $\forall c \in X$ and $x \in X^\infty$

    a) if $x \succeq \overrightarrow{\rm c}$ there exists a $\tau$ s.t. $(x_0, ..., x_t, c,c,...) \succeq \overrightarrow{\rm c}$ for all $t \geq \tau$; and
    
    b) if $x \preceq \overrightarrow{\rm c}$ there exists a $\tau$ s.t. $(x_0, ..., x_t, c,c,...) \preceq \overrightarrow{\rm c}$ for all $t \geq \tau$.

- When to Harvest a Tree example.

- **Lemma**: if $\succeq$ is continuous in the product topology, $\succeq$ is tail continuous. Proof on L8S18.

- **Theorem**: if X is connected and compact, then $\succeq$ on $\mathcal{X}$ is stationary, sensitive, jointly separable, continuous in the product topology $\iff$ $\succeq$ can be represented by U($x_0,x_1,...$) = $\sum_{t=0}^\infty \delta^t u (x_t)$ with $\delta \in (0,1)$. Moreover, $\delta$ is identified uniquely and u is cardinally unique. 

$\hookrightarrow$ *time averaging* isn't time continuous, the *overtaking criterion* is, but it's not continuous in the product topology (and also not a complete preference). Tail continuity forces $\delta < 1$. The theorem doesn't need the same $X$ each period, but does need the max possible *u* to not grow "too quickly" compared to $\delta$. 

- Let $\overrightarrow{\rm c}$ denote a constant path (c,c,...). 

- **Definition**: $\succeq '$ likes **consumption smoothing** more than $\succeq$ if $\forall c \in X$, and $x \in \mathcal{X}$, $\overrightarrow{\rm c} \succeq x \implies \overrightarrow{\rm c} \succeq' x$(Intuition, if a set of preferences like more constant choices($\overrightarrow{\rm c}$) instead of variable ones, it likes consumption smoothing more), and also $\overrightarrow{\rm c} \succ x \implies \overrightarrow{\rm c} \succ' x$. If $\succeq$ likes (or strictly prefers) a constant consumption plan more than a given alternative, so does $\succeq '$. 

- **Strzalecki Proposition**: suppose both $\succeq$ and $\succeq '$ both have discounting representations (u, $\delta$) and ($u', \delta '$) respectively, with both u and u' continuous and strictly increasing. then $\succeq'$ likes **consumption smoothing** more than $\succeq \iff$ $\delta' = \delta$ and u' = $\phi \circ u$ for some $\phi$ that is strictly increasing and concave. 

- **Constant elasticity of intertemporal substitution**: the response of $\frac{x_{t+1}}{x_t}$ is constant. This happens if the agent is maximizing $\sum_{t=0}^\infty \delta^t u(x_t)$ given a sequence of prices and u(x) = $x^\alpha$. If we extend the additively separable discounting representation to expected utiity: links the agent's risk aversion and preference for smoothing over time. This has led to some flexible specifications such as Epstein and Zin: 

\[ V_t(x) = ((1 - \delta) x_t^\rho + \delta V_{t+1} (x) ^{\rho/\alpha})^{\alpha / \rho}\]

- **Dynamic Choice**: what if the agent could re-optimize her preferences at each time *t*? We need $\succeq_t$ for each *t*. The domain of every $\succeq_t$ is $\mathcal{X} = X^{\infty}$, with the interpretation that at any *t* an agent only cares about their current and future consumption amounts (i.e. $\succeq_t$ compares consumption streams ($x_t, x_{t+1},...$) and ($y_t, y_{t+1},...$)). 

- **Dynamically Consistent**: a family of preferences $(\succeq_t)_t$ is *DC* if $\forall e \in X$ $(x_{t+1},x_t{t+2},...) \succeq_{t + 1} (y_{t+1}, y_{t+2},...)$ $\iff$ $(e,x_{t+1},x_t{t+2},...) \succeq_{t} (e,y_{t+1}, y_{t+2},...)$

- **Additive discounting is dynamically consistent** if the time-t preference maximizes: $\sum\limits_{\tau = t}\limits^{\infty} \delta^{\tau - t} u (x_t) := V_t(x)$. Here we have the familiar **dynamic programming** equation: $V_t(x) = u(x_t) + \delta V_{t+1}(x)$. We can represent the same choices with the "normalized" value function $U_t(x) := (1 - \delta) \sum_{\tau = t}^{\infty} \delta^{\tau - t} u (x_\tau)$ so that $U_t$ = ($1 - \delta$)u($x_t$) + $\delta U_{t+1}$ and value is measured in **per-period utility**.

- S25 how to **violate dynamic consistency**:

    - Sustain: Suppose that $\succeq_0$ is represented by quasi-hyperbolic preferences: $u(x_0) + \beta [\delta u (x_1) + \delta^2 u (x_2) + ...]$. If $\succeq_t$ for (t $\geq$ 1) is represented by: $u(x_t) + [ \delta u (x_{t+1}) + \delta^2 u(x_{t+2}) +...] \implies$ preferences are dynamically consistent.
    
    - Violate: if $\succeq_t$ is represented by $u (x_t) + \beta [\delta u (x_{t+1}) + \delta^2 u(x_{t+2}) + ...]$ then dynamic consistency is violated.
    
- **Recursive Utility**: the preferred choice today depends on current consumption and the value of the continuation problem, and that these don't depend on past consumption. Formally: $V_t(x) = W(x_t, V_{t+1}(x))$; with W strictly increasing in its 2nd argument and $V_t$ independent of $x_\tau$ for $\tau < t$. 

- **Time invariant preferences**: it's when the preference at t remains at t+1. Formally, if $\forall$ t,x,y $\in \mathcal{X}$ we have: $x \succeq_t y \iff x \succeq_{t+1} y$. 

- Proposition (Halevy(2015), Strzalecki 4.38): any two of the following imply the third:

    1) Stationarity of $\succeq_0$;
    
    2) Dynamic consistency of $\{ \succeq_t \}_t$; and
    
    3) Time Invariance of $\{ \succeq_t \}_t$.

## **Strzalecki Notes**{.tabset}

Not a summary, just interesting/useful insights.

### **L2**

1.1-1.8; 5.1-5.2

#### **1.1 What is decision theory about?**

The consistency conditions that characterize utility maximization are expressed in terms of axioms on observed behavior. Axiomatization breaks the model into a collection of distinct properties. Each axiom can be discussed from two different perspectives: i) *positive*: people behave this way; ii) *normative*: people should behave this way.

#### **5.1. **

##### **5.1.1. Probability Distribution**

Setting:

- **S**: all states of the world.

- **Probability distribution of the state space**: P:S$\rightarrow$[0,1] s.t. $\sum_{s \in S} P(s) = 1$. 

- **P(s)**: probability that state *s* will occur.

- **$\Delta (S)$**: all probability distributions on S. The probability distribution for all states of the world. Ex: recession 0.20, flat 0.60 and growth 0.20.

- **Event**: a collection of states. For $E \subseteq C$, the probability is given by: $P(E) = \sum\limits_{s \in E} P(S)$. This formula gives an extension of P:S $\rightarrow$[0,1] to... 

- **P:S$^2 \rightarrow [0,1]$**: a *probability measure* on S. Each probability measure must be *additive*, so that it satisfies $P(E \cup F) = P(E) + P(F)$, for all $E \cap F = \varnothing$. 

- **Probability Space**: the set of all the states of the world S equipped with a probability measure P.

##### **5.1.2. Random variables and their laws**

- **Random variables**: functions $f: S \rightarrow Z$ for some set of basic prizes. You get prize $f(s)$ if state *s* occurs.

- **Z**: the set of all outcomes z.

- **Set of random variables**: $\mathcal{F} = Z^S$.

- **EU of $f$**: $EU(f) = \sum\limits_{s \in S} u(f(s))P(s)$, where $u: Z \rightarrow \mathbb{R}$ is the Bernoulli utility function. This could be used to define a preference relation on $\mathcal{F}$.

- What is the probability of each prize *z*? Two steps:
    
    1) We identify which states lead to prize $z$ under $f$: $f^{-1} (z) := \{ s \in S: f(s) = z \}$. 
    
    2) And then we calculate their probability: $p_f (z) := P(f^{-1} (z)) = P \circ f^{-1}(z)$. $p_f$ is the probability distribution on *Z*, i.e. $p_f \in \Delta (Z)$. It is the *probability distribution*/*law of the random variable f*. 
    
- The expected utility $\forall p \in \Delta (Z)$ is: $EU(p) := \sum\limits_{z \in Z} u(z) p(z)$. By fixing P and varying $f \in \mathcal{F}$ we can trace a subset of $\Delta (Z)$. 

- When computing expected utility: state space approach > laws. For any two r.v.s f.g$\in \mathcal{F}$, their correlation is already captured by how they co-depend on the state. On the other hand, the relation between two laws $p,q \in \Delta (Z)$ is unclear, as they represent the marginal distributions of $f,g$ on $Z$ and if I care about correlations, I care about the distribution of the random vector (f,g): S $\rightarrow$ Z x Z. 

- Chapter 5 deals with **risk**:

In this chapter, we will study the theory of risk, which means we will study $\succeq$ on $\Delta (Z)$. We will call these objects *lotteries* and interpret them as *objective probabilities* that are somehow announced to the agent and he believes them fully. The usual interpretation of this situation is that the agent is choosing between lotteries with objectively given probabilities, where the randomizing devices coins, dices, and other well understood objects. We will look for axioms under which there exists $u: Z \rightarrow R$ that forms an expected utility representation. In this theory people can only differ by their utility.

- If we look at the formula for **EU(f)** we notice: a) that it is **separable** in *S* so a separability axiom will probably play a big role; b) it is **linear** in *p*.

**Dirac Measure Definition**: $\forall z \in Z$, the Dirac measure on z attaches probability 1 to z. It is denoted $\delta_z \in \Delta(Z)$ and defined by $\delta_z(z) = 1$. The set $\Delta(Z)$ is convex with Dirac measures as extreme points and the following mixture operation. The set $\Delta (Z)$ is convex with Dirac measures as extreme points and the following mixture presentation.

**Definition 5.2 - Probability Mixture**: for any two probability distributions $p,q \in \Delta(Z)$ and a number $\alpha \in [0,1]$ we define a third probability distribution $\alpha p + (1 - \alpha)q \in \Delta(Z)$ which assigns probability $\alpha p (z) + (1 - \alpha)q(z)$ to each $z \in Z$.

Example: the probability measure that attaches probability $\alpha$ to $x$ and 1 - $\alpha$ to *y* can be written as $\alpha \delta_x + (1 - \alpha)\delta_y$. It is now clear that EU is linear in probabilities. 


#### **5.2. Expected Utility with finite Z**

- **Expected Utility Model**: $\succeq$ has an EU representation if there exists a *Bernoulli utility function* $u: Z \rightarrow \mathbb{R}$ such that the function U(p) := $\sum_z u(z)p(z)$ represents $\succeq$. This model has two problems: 1) St Petersburg Paradox: people don't behave as if they maximize expected monetary value (if they did, then they would be willing to pay arbitrarily large amounts of money for lotteries with infnite expected monetary values); 2) can't explain demand for insurance since everyone is risk-neutral. Bernoulli noticed that: 1) if the utility function *u* is bounded and you maximize expected utility, St P's paradox is avoided; 2) if *u* is concave, then the model predicts people will buy insurance and have demand for diversification. 

##### **5.2.1. Independence Axiom**

- For any fixed *u*, its expectation(or more generally, the integral) is *linear in probabilities*: $\forall p,q,r \in \Delta(Z)$ and $\alpha \in (0,1])$, $p \succ q \implies \alpha p + (1 - \alpha)r \succ \alpha q + (1 - \alpha) r$. The intuition is clear: if you prefer *p* to *q*, in a *compound lottery* a choice between both combined with the same quantity of *r* will always lead to the outcome that has *p*. 

##### **5.2.2. Continuity Axioms**

- Even if Z is finite, $\Delta (Z)$ is an *uncountable* set $\implies$ we need continuity to be able to represent utility. There are 4 types of continuities on Strzalecki's noteS: 5.6 Topological; 5.7 Archimedian; 5.8 Calibration; 5.9 Mixture. I'll only get into the 5.9 here:

- $\forall$ p,q,r, $\in \Delta (Z)$, if $p \succ q \succ r$ then the sets \{ $\alpha \in [0,1] | \alpha p + (1 - \alpha)r \succ q$ \} and \{ $\alpha \in [0,1] | q \succ \alpha p + (1 - \alpha)r$ \} are open in [0,1].

##### **5.2.3. Representation Theorem**

- Theorem: suppose Z is finite. The weak order $\succeq$ satisfies axioms 5.5 and 5.9 $\iff$ it has an EU representation. Let's prove in two steps:

1) WTS: $\exists$ a linear representation of $\succeq$: 

    - *Def 5.12*: a function $U: \Delta (Z) \rightarrow \mathbb{R}$ is linear $\iff$ U($\alpha p + (1 - \alpha)q)$ = $\alpha U (p) + (1 - \alpha)U(q)$.
    
    - *Proposition 5.13*: suppose that Z is finite. A weak order $\succeq$ on $\Delta (Z)$ satisfies the independence axiom(5.5) and the mixture continuity axiom(5.9).
    
*Intuition*: here we use information about the preferences given by the axioms 5.5 and 5.9 to establish the linear property of the function U.

2) WTS: a linear representation leads to EU representation.

    - *Proposition 5.14*: a function U: $\Delta (Z) \rightarrow \mathbb{R}$ is linear $\iff$ $\exists u: Z \rightarrow \mathbb{R}$ such that U(p) = $\sum\limits_{z \in Z} u(z)p(z)$.
    
*Intuition*: we obtain a representation of *U*. To further work on the proof above, see the pgs 77-78 of the Strzalecki's notes.

- **Ordinal Uniqueness**: 

- **Cardinal Uniqueness**:








### **L3**

#### **5.4 Allais Paradox**

- **Allais Paradox**: Let Z = \{0,3,4,\} be the amounts of \$ 1000 dollar bills you might get. Consider p,p',q,q', where:

    - $p$ = $0.8 \delta_4$ + $0.2 \delta_0$ = 3.2.
    
    - $q$ = $\delta_3$ = 3.
    
    - $p'$ = $0.2 \delta_4 + 0.8 \delta_0$ = 0.8.
    
    - $q'$ = $0.25 \delta_3 + 0.75 \delta_0$ = 0.75.
    
If we compare $p$ vs $q$ and $p'$ vs $q'$, we often observe $q \succ p$ and $p' \succ q'$, which is a violation of the independence axiom since $p' = 0.25p + 0.75 \delta_0$ and $q' = 0.25 q + 0.75 \delta_0$.  

#### **5.5. Monetary Lotteries**

##### **5.5.2. Risk Aversion**

Two classifications of preferences: **absolute** and **comparative**.

- Absolute risk aversion: for any p let $\delta_{EMV (p)}$ denote the Dirac measure that for sure pays off the expected monetary value of the lottery *p* (rememeber the Certainty Equivalent example in class). 

- Definition 5.40 for Absolute Risk Attitudes: The preference $\succeq$ is:

    - **Risk-averse** whenever $\delta_{EMV (p)} \succeq p$.
    
    - **Risk-neutral** whenever $\delta_{EMV (p)} \sim p$.
    
    - **Risk-loving** whenever $\delta_{EMV (p)} \preceq p$.

**Theorem 5.41**: an EU preference is risk averse/neutral/loving $\iff$ the Bernoulli utility function is concave/affine/convex $\rightarrow$ Jensen's Inequality. 

- **Definition 5.42 for Comparative Risk Attitutdes**: the preference $\succeq_1$ is more risk averse than $\succeq_2$ whenever $\forall x \in Z, p \in \Delta(Z)$:

\begin{equation}
\delta_x \succeq_2 p \implies \delta_x \succeq_1 p \text{ and } \delta_x \succ_2 p \implies \delta_x \succ_1 p
\end{equation}

- **FOSD**: means "for sure better". Setting: $\forall p \in \Delta^{\mathcal{B}}(\mathbb{R})$, let $F_p$ be its *cdf* and $f_p$ be its *quantile function*. We say that *p FOSD q* if for any amount of money *x*, the chances of getting more than x are larger under p than under q. We can state the definition in terms of the quantile functions:

- **Lemma 5.45**: $p \geq^{FOSD} q \iff f_p(\lambda) \geq f_q(\lambda) \forall \lambda \in (0,1)$.

But it could happen that the quantile function relation $f(s) \geq g(s)$ doesn't hold, yet $p_f \geq^{FOSD} p_g$. This means that although f doesn't dominate g in each state of the world, there are rearrangements of f,g that have identical probability laws and satisfy the dominance. Thus, the relation $\geq$ on **acts** makes comparisons less frequently than the relation the relation $\geq^{FOSD}$ on **lotteries**. By the definition used, $\geq^{FOSD}$ is a refinement of $\geq$. Unsurprisingly, we have:

\[ p \geq^{FOSD} q \iff \int udp \geq \int udq \forall \text{ (weakly) increasing functions }u: \mathbb{R} \rightarrow \mathbb{R} \]

Hence, we say that a preference $\succeq$ is monotonic with respect to FOSD if it is a refinement of this partial order. 

- **SOSD**: means "more risk". Def 5.49: $p \geq^{wn} q \iff \exists$ r.v.s f,g,h on some probability space such that $p$ is the law of $f$, $q$ is the law of $g$, $\mathbb{E}(h|f) = 0$ and g = f + h. Intuition: q just adds white noise to p. Like with FOSD, we can say that a preference $\succeq$ is monotonic with respect to SOSD if it is a refinement of this partial order. In the case of SOSD we have a different definition: (Def5.52) $\succeq$ is **strongly risk averse** $\iff$  $p \geq^{SOSD} q \implies p \succeq q$.

### **L4**

5.4, 5.6.1-5.6.4

In the next chapter we will return to $\succeq$ on $\mathcal{F}$. We will call these objects *acts* and though those mappings are going to be objective the probability distribution $P \in \Delta (S)$ may not be. In real life manychoices that involve randomness are more complicated than that, as the probabilities attached to various contingencies (such as who wins an election, who wins a war, which prototype gets developed) are subjective, in that reasonable people can disagree about them, as they are one-off events so we can't rely on the long run frequencies and the law of large numbers. In those cases we will look for axioms on $\succeq$ over F under which there exists $u : Z \rightarrow \mathbb{R}$ and $P \in \Delta(Z)$ that form an expected utility representation. In this theory people can differ both by their utility and probability.



### **L5**

7.1, 7.6

#### **7.1 Uncertainty**

In reality, objective probabilities may not exist. If they don't, we work with the **Subjective Expected Utility**. We use a new model to capture this. 

- Setting:

    - S: state space.
    
    - Z: outcomes.
    
    - $Z^S$: set of acts.
    
    - $\succeq$: preference relation over some subset of the set of acts: $\mathcal{F} \in Z^S$. 
    
    - Typical elements: E,F $\subseq$ S, x,y $\in$ Z and f,g,h $\in \mathcal{F}$. 
    
    - States are mutually exclusive and collectively exhaustive.
    
    - P: subjective probability on S that is part of his preferences.
    
The idea is that the decision maker has a **subjective probability**.  

- **Subjective Expected Utility**: a preference $\succeq$ has a SEU representation if $\exists$ a probability measure P on S and a Bernoulli utility function u: Z $\rightarrow \mathbb{R}$ such that $\succeq$ is represented by:

\[ V(f) = \int_S u(f(s))  dP(s) \]

Where *u* is the risk preferences on $\Delta (Z)$ and P is the beliefs $\rightarrow$ both are part of the **preferences**. As a matter of notation, lowercase letters p; q; r, etc will denote lotteries on prizes Z that we have dealt with before. Uppercase probabilities P; Q;R denote probabilities on the state space S that we will try to reveal from the preference (along with the utility function u). We assume that utility is **state-independent**. 

#### **7.2 Savage Example**

#### **7.3 Countable Additivity**

#### **7.4 Probabilistic Sophistication**

#### **7.5 Ambiguity Aversion**

#### **7.6 Anscombe-Aumman**

Allow a little "objective" probabilities:

Given finite state space S and a finite set of outcomes Z and consider $\mathcal{F} = (\Delta Z)^2$, with preferences $\succeq$ on $\mathcal{F}$. An act f: $S \rightarrow \Delta(Z)$ in each state *s* gives you an objective lottery $f(s)$. The idea is: we have an objective randomizing device(flip of a coin) but also states S $\leftarrow$ which are one-off contingencies where reasonable people can disagree.

First the state will be realized, then the randomizing will take place.




### **L6**

#### **Chapter 2**

Now we're concerned with a sequence of choices. We model these **temporally linked decisions** (decision trees).

Consider a 2-period model. Let $Z_0 = Z_1 = \mathbb{R}_+$ represent money. Endowment: $w_0 > 0$ dollars. By spending $c_0$ at t=0, you have less available dollars on t=1 when you choose from a menu which is the interval $A_1 (c_0)$ := [0,(1 + r)($w_0 - c_0$)], where $r$ is the interest rate. The menu at t=0 is: $A_0$ := \{$(c_0,A_1(c_0)) : c_0 \in [0, w_0]$ \}. 

The set of **all possible choices** at the two periods are: **1)** at **t=0** is $X_0$ := $Z_0 \times M(Z_1)$; **2)** at **t=1** is $X_1$ := $Z_1$. Members of $M(X_0)$ are called **decision trees**. 

In t=0, the analyst observes a **choice correspondence** $c_0$ : $M(X_0) \rightarrow M(X_0)$. Given that choices at t=1 can depend of what happened on t=0, we let $\mathcal{H}_0$ denote the set of all possible histories: 

\[ \mathcal{H}_0 := \{ (A_0,x_0) \in M(X_0) \times X_0 : x_0 \in c_0(A_0) \} \]

For each menu $A_1 \in M(X_1)$ in t=1, we define the set of histories that lead to that menu:

\[ \mathcal{H}_0 (A_1) := \{ (A_0, x_0) \in \mathcal{H}_0 : x_0 = (z_0,A_1) for some z_0 \in Z_0 \]

So the choice correspondence in t=1 will be history-dependent: choice from $A_1$ may depend on how we got to $A_1$. We then write $c_1 (A_1; A_0, x_0)$ to denote the choice from menu $A_1$ after history ($A_0, x_0$) happened at t=0. We define the domain of $c_1$ as:

\[ \mathcal{D}_1 := \{ (A_1; A_0, x_0) \in M(X_1) \times \mathcal{H}_0 : (A_0, x_0) \in \mathcal{H}_0(A_1)\} \]

Now we can define the choice correspondence:

**Definition 2.2 (Dynamic Choice Correspondence):** a pair $(c_0, c_1)$ is a *dynamic choice correspondence* whenever the choice correspondence at t=0, $c_0: M(X_0) \rightarrow M(X_0)$, is such that $c_0 (A_0) \subseteq A_0 \forall A_0 \in M(X_0)$ and choice corresponde at t=1, $c_1: \mathcal{D}_1 \rightarrow M(X_1)$, is such that $c_1 (A_1; A_0, x_0) \subseteq A_1 \forall (A_1;A_0,x_0) \in \mathcal{D}_1$. 

Two things can impact period 1's choice: 1) the menu $A_0$; 2) the item $x_0 = (z_0, A_1)$ chosen from $A_1$, or the payoff $z_0$ received.

##### **Assumptions of DCC:**

- **Consequentialism**: when we are choosing between options, we *should* only be looking at their consequences. Looking forward, the past should be irrelevant. Intuitive counter-example: what you had for lunch impacts your choice for dinner. A dynamic choice correspondence ($c_0,c_1$) satisfies *consequentialism* $\iff$

\[ c_1(A_1;A_0,c_0) = c_1(A_1;B_0,x_0) \]

for all $A_1 \in M(X_1)$ and all ($A_0,x_0$), ($B_0,x_0$) $\in \mathcal{H}_0 (A_1)$. Later, notation is simplified and write $c_1(A_1;z_0)$ $\leftarrow$ this object is well defined because for any ($z_0$,$A_1$) the choice period from $A_1$ is just $c_1(A-1;A_0,x_0)$ for some ($A_0,x_0$) $\in$ $\mathcal{H}_0 (A_1)$ such that $x_0 = (z_0, A_1)$; the particular choice of $A_0$ does not matter. Intuition: the choice from menu at t=0 is represented at whatever we're choosing in t=1 given we assumed consequentialism. 

- **Payoff-History Independence**: models often also assume consequentialism + Payoff-History Independence. That is: the choice in period 1 is independent of the payoff in period 0. It makes the model more tractable, however there are a few exceptions(ex: habit formation). A dynamic choice correspondence ($c_0; c_1$) satisfes payoff-history independence if and only if:

\[ c_1(A_1;z_0) = c_1(A_1;z_0') \]

for all $A_1 \in M(X_1)$ and all $z_0, z_0' \in Z_0$.

- **No Intermediate Payoffs**: we will abstract from intermediate payoffs, i.e. assuming that $Z_0 = \{z_0 \}$ for some fixed outcome $z_0$, but we will omit $z_0$ to simplify notation; henceforth, $X_0$ becomes $M(Z_1)$. 

- **WARP**: both $c_0,c_1$ satisfy WARP. 




### **L7**

- DCC

- Strotz?


## **Other Voices**

### - [**Prospective Theory**](https://en.wikipedia.org/wiki/Prospect_theory)

#### **Summary**

- Challenges vN-M's EU theory. Describes the decision process in two stages:

    1) *Editing*: outcomes are ordered according to a certain heuristic. Individuals decide which outcomes are equivalent, set a reference point and then consider lesser outcomes as losses and greater ones as gains. This aims to alleviate framing effects. The editing process can be viewed as composed of coding, combination, segregation, cancellation, simplification and detection of dominance. 
    
    2) *Evaluation*: they compute a value (utility), based on potential outcomes and their respective probabilities, and thne choose the alternative with the higher utility.
    
The formula for the evaluation phase is:

\[ \underbrace{V}_{\text{Overall expected utility}} = \sum\limits_{i=1}\limits^{n} \underbrace{\pi}_{\text{probability weighting $f$}}(\underbrace{p_i}_{\text{outcome probability}})\underbrace{v}_{\text{$f$ that assigns value to outcome}}(\underbrace{x_i}_{\text{potential outcomes}}) \]

The value function that passes through the reference point is s-shaped and asymmetrical. Losses hurt more than gains feel good (loss aversion). This differs from expected utility theory, in which a rational agent is indifferent to the reference point. $\pi$ captures how people overreact to small events. Let (x,p;y,q) denote a prospect with outcome $x$ with probability $p$ and outcome $y$ with probability $q$ and nothing($\varnothing$) with probability 1-p-q. If (x,p;y,q) is a regular prospect (i.e., either P + q < 1, or x $\geq$ 0 $\geq$ y or x $\leq$ 0 $\leq$ y), then:

\[ V(x,p;y,q) = \pi (p) \upsilon(x) + \pi(q) \upsilon (y) \]

In Prospect Theory, $\pi$ is never linear. 

The original version of prospect theory gave rise to violations of first-order stochastic dominance. That is, prospect A might be preferred to prospect B even if the probability of receiving a value x or greater is at least as high under prospect B as it is under prospect A for all values of x, and is greater for some value of x. Later theoretical improvements overcame this problem, but at the cost of introducing intransitivity in preferences. A revised version, called cumulative prospect theory overcame this problem by using a probability weighting function derived from rank-dependent expected utility theory. Cumulative prospect theory can also be used for infinitely many or even continuous outcomes (for example, if the outcome can be any real number). An alternative solution to overcome these problems within the framework of (classical) prospect theory has been suggested as well.

### - [**Cumulative Prospective Theory**](https://en.wikipedia.org/wiki/Cumulative_prospect_theory)

#### **Summary**

The difference between this version and the original version of prospect theory is that weighting is applied to the cumulative probability distribution function, as in rank-dependent expected utility theory but not applied to the probabilities of individual outcomes. The main observation of CPT (and its predecessor Prospect Theory) is that people tend to think of possible outcomes usually relative to a certain reference point (often the status quo) rather than to the final status, a phenomenon which is called **framing effect**. Also they suffer from **loss aversion**: the same magnitude of a loss creates more negative utility than a equal-magnitude win creates positive utility. Finally, people tend to overweight extreme, but unlikely events, but underweight "average" events. The last point is in contrast to Prospect Theory which assumes that people overweight unlikely events, independently of their relative outcomes.

CPT incorporates these observations in a modification of Expected Utility Theory by replacing final wealth with payoffs relative to the reference point, replacing the utility function with a value function that depends on relative payoff, and replacing cumulative probabilities with weighted cumulative probabilities. In the general case, this leads to the following formula for subjective utility of a risky outcome described by probability measure {\displaystyle p}p:

\[ U(p):=\int _{-\infty}^{0}v(x){\frac {d}{dx}}(w(F(x)))\,dx+\int _{0}^{+\infty }v(x){\frac {d}{dx}}(-w(1-F(x)))\,dx, \]

Where now we divided the outcomes into negative(first integral) and positive(second integral) ones.

#### Differences from Prospect Theory

To avoid the issue from PT violating FOSD, cumulative probabilities are transformed, rather than the probabilities themselves. This leads to the aforementioned overweighting of extreme events which occur with small probability, rather than to an overweighting of all small probability events. 

### [**Rank-dependent Expected Utility**](https://en.wikipedia.org/wiki/Rank-dependent_expected_utility)

#### **Summary**

The rank-dependent expected utility model (originally called anticipated utility) is a generalized expected utility model of choice under uncertainty, designed to explain the behaviour observed in the Allais paradox, as well as for the observation that many people both purchase lottery tickets (implying risk-loving preferences) and insure against losses (implying risk aversion). 

A natural explanation of these observations is that individuals overweight low-probability events such as winning the lottery, or suffering a disastrous insurable loss. In the **Allais paradox**, individuals appear to forgo the chance of a very large gain to avoid a one per cent chance of missing out on an otherwise certain large gain, but are less risk averse when offered the chance of reducing an 11 per cent chance of loss to 10 per cent.

A number of attempts were made to model preferences incorporating probability theory, most notably the original version of prospect theory, presented by Daniel Kahneman and Amos Tversky (1979). However, all such models involved violations of first-order stochastic dominance. In prospect theory, violations of dominance were avoided by the introduction of an 'editing' operation, but this gave rise to violations of transitivity. 

**Intuition**: The crucial idea of rank-dependent expected utility was to overweigh *only unlikely extreme outcomes*, rather than all unlikely events. Formalising this insight required transformations to be applied to the cumulative probability distribution function, rather than to individual probabilities.

#### **Formal Representation**

As the name implies, the rank-dependent model is applied to the increasing rearrangement **y**$_{\text{[ ]}}$ of **y** which satisfies $y_{[1]} \leq y_{[2]} \leq ... \leq y{[S]}$. 

\[ W(y) = \sum\limits_{s \in \Omega} h_{[s]} (\pi) u(y_{[s]}) \]

Where $\pi \in$ II, u: $\mathbb{R} \rightarrow \mathbb{R}$ and $h_{[s]} (\pi)$ is a probability weight such that

\[ h_{[s]} (\pi) = q(\sum\limits_{t=1}\limits^{s} \pi_{[t]}) - q (\sum\limits_{t=1}\limits^{s-1} \pi_{[t]}) \]

For a transformation function $q: [0,1] \rightarrow [0,1]$ with q(0) = 0, q(1) = 1.

Note that $\sum\limits_{s \in \Omega} h_{[s]} (\pi) = q (\sum\limits_{t=1}\limits^{S} \pi_{[t]}) = q(1) = 1$ so that the decision weights sum to 1.















