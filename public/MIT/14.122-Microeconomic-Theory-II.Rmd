---
output: html_document
---

# 14.121 - Microeconomic Theory I{.tabset}

## **Lectures**{.tabset}

### **Lecture 1**

- PSNE in discrete games. 

1) Check all boxes. 

2) S is a PSNE $\iff$ $S_i^\ast \in BR_i(S_i^\ast) \forall i$.

3) PSNE $\subset S^\infty$.

### **Lecture 2**

- PSNE in continuous games.

- 1st ex: **Cournot Competition**

2 firms choose $q_1$ and $q_2$, market determines price.

$S_1 = S_2 = \mathbb{R}^+$

$u_1 (q_1,q_2) = q_1 (1- (q_1 + q_2))$

**finish copying from notebook!**

- Will finally arrive at Unique NE

- 2nd ex: Hotelling(1929) competition on a line

- 3rd ex: Price Competition with Logit Demands

### **Lecture 3**

- **Multiple equilibria**: Brexit game.

- Nonexistence and **Mixed Equilibria**.

- **Mixed Strategy**.

### **Lecture 4**

*Nov 4th*

Full Support NE in 3x3 Games:

- Larger games: iterated dominance; clever observation

- Correlated Equilibrium

### **Lecture 5**

*Nov 6th*

- **Theorem: Every finite normal form game has a Nash Equilibrium.**

Pf

- **Kakutani's Theorem**

- **Glicksberg Proposition**

### **Lecture 6**

- **Extensive Form Games**

    - **Firm Entry Game**

    - **Matching Pennies Game**

- **Stackelberg Competition**

- **Subgame Perfect Equilibrium**

- [**Subgame Perfect Nash Equilibrium**](https://en.wikipedia.org/wiki/Nash_equilibrium)



## **Content** {.tabset}

### 1.1 Introduction to Games in Strategic Form and Iterated Strict Dominance

**Strategic Form Games**: have three elements: 

  i) **set of players** $i \in \mathcal{I}$, which we take to be the finite set $\{1,2,...I\}$.
  
  ii) the **pure-strategy space** $S_i$ for each player *i*.
  
  iii) **payoff function** $u_i$ that five player i's von Neumann-Morgenstern utility $u_i$(s) for each profile s = ($s_1,...,s_I$) of strategies.

The structure of the game is *common knowledge*. 

**Pure strategy**: what are the options of movement. Ex: up or down.

**Mixed strategy** $\sigma_i$: is a probability distribution over pure strategies. The space of player i's mixed strategies is denoted by $\sum_i$, where $\sigma_i (s_i)$ is the probability that $\sigma_i$ assigns to $s_i$. The **support** of a mixed strategy $\sigma_i$ is the set of pure strategies to which $\sigma_i$ assigns positive probability. 

**Dominated strategy**: is a strategy that yields gives a smaller payoff than another strategy no matter how player 1 plays. 

**Iterated dominance**: when you have a dominated strategy, you can anticipate which moves can be made. For ex: knowing that P1 won't play Up, P2 eliminates playing Left from his set of strategies. 

A pure strategy may be strictly dominated by a mixed strategy even if it is not strictly dominated by any pure strategy. 

### 1.2 Nash Equilibrium

A Nash Equilibrium is a profile of strategies such that each players's strategy is an optimal response to the other players' strategies. **Definition**: a mixed-strategy profile $\sigma^\ast$ is a Nash Equilibrium if, $\forall$ i, $u_i(\sigma_i^\ast , \sigma_{-i}^\ast) ≥ u_i (s_i, \sigma_{-i}^\ast) \forall si \in S_i$. 

A Nash Equilibrium is **strict** if each player has a unique best response to his rivals' strategies. That is, $s^\ast$ is a strict equilibrium $\iff$ it is a NE and, $\forall i$ and all $s_i ≠ s_i^\ast$ we have: $u_i(s_i^\ast , s_{-i}^\ast) > u_i (s_i, s_{-i}^\ast)$. A strict equilibrium is **necessarily** a pure-strategy equilibrium. 

Examples of Pure-Strategy Equilibria:

1.3 - Cournot Competition

1.4 - Hotelling Competition

1.5 - Majority Voting

#### 1.2.3 Nonexistence of a Pure-Strategy Equilibrium

1.6 - Matching Pennies game: the only *stable* situation is one in which each player randomizes between his two pure strategies, assigning equal probability to each. As far as his payoff goes, he could just as well play "heads" with certainty, but if this is anticipated by player 2 the equilibrium disintegrates. 

### 1.3 Existence and Properties of Nash Equilibria



#### 2.1.1 Iterated Strict Dominance

#### 2.1.2 An Application of Iterated Strict Dominance

### 2.2 Correlated Equilibrium

### 3.3 Extensive Form

#### 3.4.2 The Strategic-Form Representation of Extensive-Form Games

### 3.5 Backward Induction and Subgame Perfection

### 4.2 The Principle of Optimality and Subgame Perfection

### 4.3 A First Look at Repeated Games

### 5.1 Repeated Games with Observable Actions

### 6.1-6.5 Static Games of Incomplete Information

### 6.7 Using Bayesin Equilibria to Justify Mixed Equilibria

### 8.1 - 8.2 Dynamic Games of Incomplete Information

#### 8.3.2 Sequential Equilibrium

### 11.2 Signaling Games

### 12.1 Generic Properties of Nash Equilibria

## **Game Theory (FT)**{.tabset}

### **Overview**

### **Part I - Static Games**{.tabset}

#### A. Modeling strategic interaction

Readings: (FT 1.1, 2.1.1, 2.1.2; G 1.1AB)

#### B. Nash Equilibrium

Readings: (FT 1.2; G 1.1C, 1.2)

#### C. Mixed strategies 

Readings: (FT 1.1, 1.2.3; G 1.3)

#### D. Existence theorems, correlated equilibrium 

Readings: (FT 1.3, 12.1, 2.2; G 1.3)

### **Part II - Dynamic Games**{.tabset}

#### A. Extensive form games 

Readings: (FT 3.3, 3.4.2, 3.5; G 2.1, 2.4)

#### B. Subgame perfection 

Readings: (FT 3.5; G 2.2)

#### C. Examples, repeated games, Markov equilibrium 

Readings: (FT 4.2, 4.3, 5.1; G 2.3)

#### **5) Repeated Games**

**Repeated Games** are the ones in which players face the same "stage game". If the players actions' are observed at the end of each period, it becomes possible for players to condition their play on the past play of their opponents, which can lead to equilibrium outcomes that don't arise when the game is played only once. The profile where both players use the unrelenting strategy until an opponent defects is a SPE of the infinitely repeated game if the discount factor($\delta$) is sufficiently close to 1. For a patient player, even though it yields a nice short term payoff, the gain is outweighed by the prospect of future "punishment". The reason repeated play introduces new equilibrium is that **players can condition their play based on the information they have received in previous stages**. 

##### **5.1. The Model**

Setting: the game that is repeated is called the *stage game*. It is a finite I-player simultaneous-move game with finite action spaces $A_i$ and stage-game payoff functions $g_i$ : A $\rightarrow \mathbb{R}$ where A = $x_{i \in \mathcal{I}}A_i$. Let $A_i$ be the space of probability distributions over $A_i$. The players **observe** the realized actions at the end of each period. $a^t = (a_i^t,...,a_I^t)$: actions played in period *i*. Suppose that the game begins in period 0, with the null history $h^0$. For t ≥ 1, let $h^t$ = ($a^0,a^1,...,a^{t-1}$) be the realized choices of actions at all periods before t, and let $H^t$ = $(A)^t$ be the space of all possible period-t histories. A player's strategy can't depend on the past values of his opponents' randomizing probabilities.

We focus on the case where players discount future utilities using discount factor $\delta < 1$. In this game (G($\delta$)), player's i objective function is to maximize the normalized sum:

\[ u_i = E_\sigma (1 - \delta) \sum_{t = 0}^\infty \delta^t g_i (\sigma^t (h^t))\]

Where $E_{\sigma}$ denotes the expectation with respect to the distribution over infinite histories that is generated by strategy profile $\sigma$. 

In this case, a **Nash Equilibrium** of the stage game (a static equilibrium) happens when the strategies "each player *i* plays $\alpha_i^\ast$ from now on" are a SPE. If the game has *m* static equilibria $\{ \alpha^j \} _{j=1}^m$, then for any map j(t) from time periods to indices the strategies "play $\alpha^{j(t)}$ in period t" are a SPE as well. 

##### **5.1.2. The Folk Theorem for Infinitely Repeated Games**

If players are sufficiently patient then any feasible, individually rational payoffs can be enforced by an equilibrium. Thus, in the limit of extreme patience, repeated play allows virtually any payoff to be an equilibrium outcome. Player i's reservation utility or minimax value is:

\[ \underline{v}_i = min_{\alpha - j}[max_{\alpha i} g_i(\alpha_i, \alpha_{-i})]\]

The above equation represents the lowest payoff player i's opponents can hold him to by any choice of $\alpha_{-i}$, provided that player *i* correctly foresees $\alpha_{-i}$ and plays a best response to it. Let $m_{-i}^i$ be a strategy for player i's opponents that attains the minimum in equation above. We call $m_{-i}^i$ the minmax profile against player i. Let $m_{-i}^i$ be a strategy for player i such that $g_i(m_{i}^i,m_{-i}^i) = \underline{v}_i$.





### **Part III - Incomplete Information**{.tabset}

#### A. Types, Bayesian equilibrium, examples 

Readings: (FT 6.1-6.5, 6.7; G 3.1-3.2)

### **Part IV - Dynamic Games with Incomplete Information**{.tabset}

#### A. PBE concept, signalling

Readings: (FT 8.1-8.2; G 4.1-4.2, 4.3C)

#### B. Refinements, cheap talk 

Readings: (FT 8.3.2, 11.2; G 4.4)




## **Interesting Concepts**

### **Interesting Concepts**

- Strategic-Form Games: have 3 elements: 1) **set of players** $i \in \mathcal{I}$, which we take to be the finite set $\{1,2,...,I\}$; 2) the **pure-strategy space** $S_i$ for each player *i*; 3) **payoff functions** $u_i$ that give player i's utility $u_i(s)$ for each profile s = ($s_1,...,s_I$) of strategies.

- Structure of game: *common knowledge*: all players know the structure of the strategic form and know that their opponents know it, and know that their opponents know that they know. 

- **Pure strategy**: options each player has. Ex: Left or Right.

- **Mixed strategy** $\sigma_i$ is a probability distribution over pure strategies. Space of mixed strategies: $\sum_i$ where $\sigma_i(s_i)$ is the probability that $\sigma_i$ assigns to $s_i$. The **support** of a mixed strategy $\sigma_i$ is the set of pure strategies to which $\sigma_i$ assigns positive probability. 

- **Degenerate pure strategy**: a mixed strategy that assigns probability 1 to $s_i$ and probability 0 to all other strategies of player *i*. 

- **Strictly Dominated**: a strategy whose payoff is always lower than the payoff(s) of other strategy(ies). If we eliminate the strategies that are strictly dominated we have what is called the **iterated (strict) dominance**. A pure strategy may be strictly dominated by a mixed strategy even if it is not strictly dominated by any pure strategy. **Weakly dominated** happens when you have at least one strict dominance in the relation and all the others are at least as good as. 

- **Nash Equilibrium**: a profile of strategies such that each player's strategy is an optimal response to the other players strategies. A mixed-strategy profile $\sigma^\ast$ is a *Nash equilibrium* if, $\forall$ players *i*: $u_i (\sigma_i^\ast, \sigma_{-i}^\ast) ≥ u_i(s_i, \sigma_{-i}^\ast) \forall s_i \in S_i$. A Nash equilibrium is *strict* if each player has a unique best response, so that the last equation is strict. By definition, this is obviously a pure-strategy scenario. 

- Games examples:

**Cournot model**: **duopoly model** producing a **homogeneous good**. The **strategies are quantities**. Firms simultaneously choose respective output levels. They sell their output at the **market-clearing price p(q)**. Cost of production is $c_i(q_i)$ and firm i's total profit is: $u_i(q_1,q_2) = q_i p(q) - c_i(q_i)$. Feasible sets $Q_i$ of output levels and the payoff functions $u_i$ determine the strategic form of the game. The **Cournot Reaction Functions** $r_1 : Q_2 \rightarrow Q_1$ and $r_2 : Q_1 \rightarrow Q_2$ specify each firm's optimal output for each fixed output level of its opponent. FOC: $p(q_1 + r_2(q_1)) + p'(q_1 _ r_2(q_1))r_2(q_1) - c_2'(r_2(q_1)) = 0$. The intersections (if $\exists$) of the two reaction functions are the NE of the Cournot game: no firm can gain from changing output given the output of the opponent. For instance, for linear demand (p(q) = max(0,1-q)) and symmetric, linear cost ($c_i(q_i) = cq_i$) where 0 ≤ c ≤ 1), firm 2's reaction function, given above is: $r_2(q_1) = (1 - q_1 - c)/2$, and by symmetry firm 1's reaction function is: $r_1(q_2) = (1 - q_2 - c)/2$. The NE satisfies $q_2^\ast = r_2(q_1^\ast)$ and $q_1^\ast = r_1 (q_2^\ast)$ or $q_1^\ast = q_2^\ast = (1 - c)/3$.
    
**Hotelling model**: 
    
**3-people voting model(Brexit example)**: 

- Technical/Proofs: see FT pg 29. 

- **Extensive-form games**: we include the notion of time. It makes explicit the order in which players move and what each player knows when making each of his decisions. 

- **Empty threat**: if the second player to make a move were to hold his output regardless of the first player's choice, this would be an empty threat becuse the threatened player could simply choose in a way that the second player would end up changing his choice because he would have a better output. This is consistent with the concept of **backward induction**: solving for the optimal choice of the last mover for each possible situation and then work backwards for every move until we get to the starting point.

- **Subgame-perfect equilibrium**: games in which players move simultaneously in several periods. There are several last-movers and each of them must know the moves of the others to compute his own optimal choice. Each path/history generates a simultaneous move game between the two firms and firm 1 forecasts that play in this game will correspond to an equilibrium for the payoffs prevailing under the path/history. The key feature of a subgame is that it, when seen in isolation, constitutes a game in its own right. When the initial node of a subgame is reached in a larger game, players can concentrate only on that subgame; they can ignore the history of the rest of the game (provided they know what subgame they are playing). 

- **Public Good Game**: suppose we know the classic payoff matrix for this game. So we know that the u(C) = 1 - $c_1$, and u(D) = 1 p + (1 - p) 0 = p. So we equal both equations: 1 - $c_1$ = p. "p" is the probability that P2 contributes. There is one unique solution: 









