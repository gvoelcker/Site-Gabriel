---
output: html_document
---

# 14.381 - Statistical Methods{.tabset}

## Lecture 1

Based on [**this**](https://gabrielvoelcker.netlify.com/mit/14.381_lec1.pdf). Introduction. Short summary of probabilistic concepts. Normal distribution.

### 1 Random Variables

#### 1.1 Basic Definitions 

[**Random Variable**](https://en.wikipedia.org/wiki/Random_variable). There are 3 types:

1) [**Discrete**](https://en.wikipedia.org/wiki/Random_variable#Standard_case).

2) [**Continuous**](https://en.wikipedia.org/wiki/Random_variable#Continuous_random_variable).

3) [**Mixed**](https://en.wikipedia.org/wiki/Random_variable#Mixed_type).

[**Cdf definition**](https://en.wikipedia.org/wiki/Cumulative_distribution_function).

#### 1.2 Functions of Random Variables

[**Definition**](https://en.wikipedia.org/wiki/Random_variable#Functions_of_random_variables)

Suppose we have random variable X and function g : $\mathbb{R}$ -> $\mathbb{R}$. Then we can defi􏰀ne another random variable Y = g(X). The cdf of Y can be calculated as follows:

$F_Y$(t) = P {Y ≤ t} = P{g(X) ≤ t} = P{X $\in$ $g^{-1}$ (-$\infty$,t]},

where $g^{-1}$ may be the set-valued inverse of *g*. The set $g^{-1}(-\infty,t]$ consists of all s $\in$ $\mathbb{R}$ such that g(x) $\in$ (-$\infty$,t] i.e. g(s) ≤ t. If g is strictly increasing and continuously differentiable then it has strictly increasing and continuously differentiable inverse $g^{-1}$ defined on set g($\mathbb{R}$). In this case P{X $\in$ $g^{-1}$(-$\infty,t$]} = P{X ≤ $g^{-1}$(t)} = $F_X(g^{-1}(t))$ for all t $\in$ g($mathbb{R}$). If in addition, X is a continuous random variable, then ......


#### 1.3 [**Expected Value**](https://en.wikipedia.org/wiki/Expected_value)

The **Expected Value** of a random variable, intuitively, is the long-run average value of repetitions of the same experiment it represents.

##### 1.3.1 [**Properties of Expectation**](https://en.wikipedia.org/wiki/Expected_value#Basic_properties)

- E[$1_A$] = P(A)

- If X = Y, then E[X] = E[Y]

- Expected value of a constant.

- Linearity.

- E[X] exists and is finite if and only if E[|X|] is finite.

- If X ≥ 0 (a.s.) then E[X] ≥ 0.

- Monotonicity.

- If |X| ≤ Y (a.s.) and E[Y] is finite then so is E[X].

- If E|$X^ß$ < $\infty$ and 0 < $\alpha$ < ß then E|$X^\alpha$| < $\infty$

- Extremal Property.

- Non-degeneracy.

- If E[X] < $+\infty$ then X < $+\infty$

- Non-multiplicativity.

- Countable non-additivity.

- Countable additivity for non-negative random variables.

#### 1.4 Examples of Random Variables

### 2 [**Bivariate (multivariate) distributions**](https://en.wikipedia.org/wiki/Joint_probability_distribution)

Given random variables X,Y, that are defined on a probability space, the joint probability distribution for X,Y, is a probability distribution that gives the probability that each of X,Y, falls in any particular range or discrete set of values specified for that variable. In the case of only two random variables, this is called a bivariate distribution, but the concept generalizes to any number of random variables, giving a multivariate distribution.

#### 2.1 [**Joint, marginal, conditional**](https://sites.nicholas.duke.edu/statsreview/jmc/)

[**Marginal probability**](https://en.wikipedia.org/wiki/Marginal_distribution): is the probability distribution of the variables contained in the subset. It gives the probabilities of various values of the variables in the subset without reference to the values of the other variables.

[**Joint probability**](https://www.investopedia.com/terms/j/jointprobability.asp): is a statistical measure that calculates the likelihood of two events occurring together and at the same point in time. Joint probability is the probability of event Y occurring at the same time that event X occurs.

[**Conditional probability**](https://en.wikipedia.org/wiki/Conditional_probability): is a measure of the probability of an event occurring given that another event has (by assumption, presumption, assertion or evidence) occurred.

#### 2.2 Independence

#### 2.3 [**Covariance**](https://en.wikipedia.org/wiki/Covariance)

Covariance is a measure of the joint variability of two random variables. If the greater values of one variable mainly correspond with the greater values of the other variable, and the same holds for the lesser values, (i.e., the variables tend to show similar behavior), the covariance is positive.

### 3 [**Normal Random Variables**](https://en.wikipedia.org/wiki/Normal_distribution)

#### 3.1 [**Conditional Distribution**](https://www.statisticshowto.datasciencecentral.com/conditional-distribution/)

A conditional distribution is a probability distribution for a sub-population. In other words, it shows the probability that a randomly selected item in a sub-population has a characteristic you’re interested in. 

## Lecture 2

### 1 Useful Inequalities

[**Markov's Inequality**](https://en.wikipedia.org/wiki/Markov%27s_inequality): gives an upper bound for the probability that a non-negative function of a random variable is greater than or equal to some positive constant. [**Intuition**](https://www.youtube.com/watch?v=4nHcPJsxyv8).

[**Chebyshev's Inequality**](https://en.wikipedia.org/wiki/Chebyshev%27s_inequality): guarantees that, for a wide class of probability distributions, no more than a certain fraction of values can be more than a certain distance from the mean.

[**Hölder's Inequality**](https://en.wikipedia.org/wiki/H%C3%B6lder%27s_inequality): is a fundamental inequality between integrals and an indispensable tool for the study of $L^p$ spaces.

### 2 [**Convergence in Probability**](https://en.wikipedia.org/wiki/Convergence_of_random_variables) and [**Law of Large Numbers**](https://en.wikipedia.org/wiki/Law_of_large_numbers).

Is a theorem that describes the result of performing the same experiment a large number of times. According to the law, the average of the results obtained from a large number of trials should be close to the expected value, and will tend to become closer as more trials are performed.



### 3 [**Weak Convergence**](https://en.wikipedia.org/wiki/Law_of_large_numbers#Weak_law) and [**Central Limit Theorem**](https://en.wikipedia.org/wiki/Central_limit_theorem)

CLT: the central limit theorem (CLT) establishes that, in some situations, when independent random variables are added, their properly normalized sum tends toward a normal distribution (informally a "bell curve") even if the original variables themselves are not normally distributed. The theorem is a key concept in probability theory because it implies that probabilistic and statistical methods that work for normal distributions can be applicable to many problems involving other types of distributions.

### 4 Asymptotic statements derived from basic limit theorems

[**Slutsky's Theorem**](https://en.wikipedia.org/wiki/Slutsky%27s_theorem)

[**Continuous Mapping Theorem**](https://en.wikipedia.org/wiki/Continuous_mapping_theorem)

#### 4.1 Symbols $o_p$ and $O_p$

### 5 Delta Method

#### 5.1 Example


## **Useful Info**{.tabset}

### Schedule

[**Schedule**](https://gabrielvoelcker.netlify.com/mit/schedule_2018.pdf)

### Material

[**Statistical Inference - Casella & Berger**](https://gabrielvoelcker.netlify.com/mit/Casella Berger - Statistical Inference.pdf)

[**All of Statistics - Wasserman**](https://gabrielvoelcker.netlify.com/mit/Wasserman - All of Statistics.pdf)

### Problem Sets


### Exams

[**Midterm 2018**](https://gabrielvoelcker.netlify.com/mit/midterm_exam_fall12.pdf)

[**Midterm 2018 Solutions**](https://gabrielvoelcker.netlify.com/mit/midterm_exam_fall12_solutions.pdf)

